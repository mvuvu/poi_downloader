{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 增强版POI爬虫 v2.0 🚀\n\n## 🆕 最新特性 (2025-07-02)\n- 🔥 **统一程序入口** - 所有功能集成到一个程序\n- 🔇 **完全静默运行** - 屏蔽所有Chrome警告信息\n- 📊 **9个增强字段** - 评论数量、电话、网站、营业时间、价格等级\n- ⚡ **4倍并发优化** - 智能WebDriver池，高效处理\n- 🛡️ **稳定可靠** - 多策略元素定位，智能重试机制\n- 💾 **断点续爬** - 自动检查点，支持大规模数据收集\n- 🧪 **测试模式** - 快速验证环境和功能\n- 📂 **智能文件选择** - 自动扫描并选择最大CSV文件\n\n## 🔧 推荐使用方式\n1. **首次使用**: 运行测试模式验证环境\n2. **小规模验证**: 处理部分地址确认效果\n3. **生产运行**: 开启全量爬取获取完整数据",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 导入必要的库\nimport pandas as pd\nimport numpy as np\nimport time\nimport json\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# 导入增强版爬虫模块\nfrom final_crawler import FinalPOICrawler\nfrom simple_file_selector import SimpleFileSelector, get_simple_file_config\n\nprint(\"📦 所有模块导入成功！\")\nprint(f\"📅 当前时间: {pd.Timestamp.now()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 1. 配置设置"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 🔥 新功能：智能文件选择器\nENABLE_FILE_SELECTION = True  # 设置为True启用文件选择，False使用默认文件\n\nif ENABLE_FILE_SELECTION:\n    print(\"📂 启动智能文件选择器...\")\n    print(\"=\" * 50)\n    \n    # 使用简化的文件选择器\n    file_config = get_simple_file_config(suffix=\"poi_notebook\")\n    \n    if file_config['has_input']:\n        INPUT_FILE = file_config['input_file']\n        OUTPUT_FILE = file_config['output_file']\n        \n        print(f\"✅ 文件选择完成:\")\n        print(f\"📥 输入文件: {INPUT_FILE}\")\n        print(f\"📤 输出文件: {OUTPUT_FILE}\")\n        \n        # 显示文件信息\n        try:\n            df_check = pd.read_csv(INPUT_FILE)\n            print(f\"📊 文件信息: {len(df_check):,} 行, 列: {list(df_check.columns)}\")\n        except Exception as e:\n            print(f\"⚠️ 无法读取文件信息: {e}\")\n            \n    else:\n        print(\"❌ 未找到可用的CSV文件，使用默认配置\")\n        INPUT_FILE = 'data/input/千代田区_complete_1751433587.csv'\n        OUTPUT_FILE = 'data/output/千代田区_poi_notebook.csv'\n\nelse:\n    # 使用默认文件\n    print(\"📄 使用默认文件配置\")\n    INPUT_FILE = 'data/input/千代田区_complete_1751433587.csv'\n    OUTPUT_FILE = 'data/output/千代田区_poi_notebook.csv'\n\nprint(f\"\\n📋 最终配置:\")\nprint(f\"  输入: {INPUT_FILE}\")\nprint(f\"  输出: {OUTPUT_FILE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 1. 文件选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ 最终运行配置:\n",
      "  📝 max_workers: 4\n",
      "  📝 driver_pool_size: 4\n",
      "  📝 batch_size: 15\n",
      "  📝 timeout: 12\n",
      "  📝 retry_times: 2\n",
      "  🔥 headless: True\n",
      "  📝 checkpoint_interval: 30\n",
      "  🔥 input_file: data/input/千代田区_complete_1751433587.csv\n",
      "  🔥 output_file: data\\output\\千代田区_1751433587_poi_notebook_20250702_1632.csv\n"
     ]
    }
   ],
   "source": [
    "# 🔥 动态配置 - 基于文件选择结果\n",
    "CONFIG = {\n",
    "    'max_workers': 4,          # 并发线程数\n",
    "    'driver_pool_size': 4,     # WebDriver池大小\n",
    "    'batch_size': 15,          # 批量保存数据量\n",
    "    'timeout': 12,             # 页面加载超时时间(秒)\n",
    "    'retry_times': 2,          # 重试次数\n",
    "    'headless': True,          # 🔥 强制无头模式 - 不显示Chrome窗口\n",
    "    'checkpoint_interval': 30, # 检查点保存间隔\n",
    "    'input_file': INPUT_FILE,  # 🔥 使用选择的输入文件\n",
    "    'output_file': OUTPUT_FILE # 🔥 使用生成的输出文件\n",
    "}\n",
    "\n",
    "print(\"⚙️ 最终运行配置:\")\n",
    "for key, value in CONFIG.items():\n",
    "    icon = \"🔥\" if key in ['headless', 'input_file', 'output_file'] else \"📝\"\n",
    "    print(f\"  {icon} {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 2. 数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 成功读取输入文件: data/input/千代田区_complete_1751433587.csv\n",
      "📊 数据统计:\n",
      "  总行数: 8,693\n",
      "  列名: ['District', 'Latitude', 'Longitude', 'Address']\n",
      "\n",
      "📋 数据预览:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>千代田区</td>\n",
       "      <td>35.690357</td>\n",
       "      <td>139.771265</td>\n",
       "      <td>東京都千代田区鍛冶町1丁目7-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>千代田区</td>\n",
       "      <td>35.686220</td>\n",
       "      <td>139.734724</td>\n",
       "      <td>東京都千代田区二番町10-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>千代田区</td>\n",
       "      <td>35.695114</td>\n",
       "      <td>139.762307</td>\n",
       "      <td>東京都千代田区神田小川町3丁目6-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>千代田区</td>\n",
       "      <td>35.690443</td>\n",
       "      <td>139.773287</td>\n",
       "      <td>東京都千代田区鍛冶町1丁目10-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>千代田区</td>\n",
       "      <td>35.703297</td>\n",
       "      <td>139.770201</td>\n",
       "      <td>東京都千代田区外神田6丁目5-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  District   Latitude   Longitude             Address\n",
       "0     千代田区  35.690357  139.771265    東京都千代田区鍛冶町1丁目7-1\n",
       "1     千代田区  35.686220  139.734724     東京都千代田区二番町10-46\n",
       "2     千代田区  35.695114  139.762307  東京都千代田区神田小川町3丁目6-2\n",
       "3     千代田区  35.690443  139.773287   東京都千代田区鍛冶町1丁目10-7\n",
       "4     千代田区  35.703297  139.770201    東京都千代田区外神田6丁目5-9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📍 有效地址数量: 8,693\n",
      "📍 示例地址:\n",
      "  1. 東京都千代田区鍛冶町1丁目7-1\n",
      "  2. 東京都千代田区二番町10-46\n",
      "  3. 東京都千代田区神田小川町3丁目6-2\n"
     ]
    }
   ],
   "source": [
    "# 读取并预览输入数据\n",
    "try:\n",
    "    df_input = pd.read_csv(CONFIG['input_file'])\n",
    "    print(f\"📄 成功读取输入文件: {CONFIG['input_file']}\")\n",
    "    print(f\"📊 数据统计:\")\n",
    "    print(f\"  总行数: {len(df_input):,}\")\n",
    "    print(f\"  列名: {list(df_input.columns)}\")\n",
    "    \n",
    "    print(f\"\\n📋 数据预览:\")\n",
    "    display(df_input.head())\n",
    "    \n",
    "    # 准备地址列表\n",
    "    addresses = df_input['Address'].dropna().tolist()\n",
    "    print(f\"\\n📍 有效地址数量: {len(addresses):,}\")\n",
    "    print(f\"📍 示例地址:\")\n",
    "    for i, addr in enumerate(addresses[:3], 1):\n",
    "        print(f\"  {i}. {addr}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 读取输入文件失败: {e}\")\n",
    "    addresses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 3. 小规模测试 (可选)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 测试前5个地址\nTEST_MODE = True  # 设置为False跳过测试，直接全量运行\nTEST_COUNT = 5\n\nif TEST_MODE and addresses:\n    print(f\"🧪 测试模式: 处理前 {TEST_COUNT} 个地址\")\n    \n    test_config = CONFIG.copy()\n    test_config['output_file'] = 'data/output/测试结果_poi.csv'\n    test_config['max_workers'] = 2  # 测试时减少并发\n    \n    test_addresses = addresses[:TEST_COUNT]\n    \n    print(f\"🚀 开始测试爬取...\")\n    start_time = time.time()\n    \n    # 清理测试模式的检查点\n    checkpoint_file = Path('checkpoint.json')\n    if checkpoint_file.exists():\n        checkpoint_file.unlink()\n        print(\"🧹 已清理检查点文件\")\n    \n    crawler = FinalPOICrawler(test_config)\n    try:\n        crawler.process_addresses(test_addresses)\n        \n        elapsed = time.time() - start_time\n        print(f\"\\n⏱️ 测试完成，耗时: {elapsed:.1f} 秒\")\n        print(f\"📈 平均速度: {elapsed/TEST_COUNT:.1f} 秒/个\")\n        \n        # 查看测试结果\n        if Path(test_config['output_file']).exists():\n            test_results = pd.read_csv(test_config['output_file'])\n            print(f\"\\n📊 测试结果统计:\")\n            print(f\"  总POI数: {len(test_results)}\")\n            \n            if len(test_results) > 0:\n                print(f\"\\n📋 增强数据字段预览:\")\n                display(test_results.head())\n                \n                print(f\"\\n📈 数据质量统计:\")\n                print(f\"  有评分的POI: {test_results['rating'].notna().sum()}\")\n                print(f\"  有评论数的POI: {test_results['review_count'].notna().sum()}\")\n                print(f\"  有电话的POI: {test_results['phone'].notna().sum()}\")\n                print(f\"  有网站的POI: {test_results['website'].notna().sum()}\")\n        \n    except Exception as e:\n        print(f\"❌ 测试失败: {e}\")\n    finally:\n        crawler.close()\n        \nelse:\n    print(\"⏭️ 跳过测试模式\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 4. 全量生产爬取"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 确认是否执行全量爬取\nRUN_FULL_CRAWL = False  # 设置为True开始全量爬取\n\nif RUN_FULL_CRAWL and addresses:\n    print(f\"🎯 开始全量POI爬取\")\n    print(f\"📊 预计处理 {len(addresses):,} 个地址\")\n    print(f\"⚡ 性能设置: {CONFIG['max_workers']} 并发线程，无头模式\")\n    \n    estimated_time = len(addresses) * 2.5 / CONFIG['max_workers'] / 60  # 估算时间\n    print(f\"⏱️ 预计耗时: {estimated_time:.1f} 分钟\")\n    \n    confirmation = input(\"\\n确认开始全量爬取？(输入 'yes' 确认): \")\n    \n    if confirmation.lower() == 'yes':\n        print(f\"\\n🚀 开始全量爬取...\")\n        start_time = time.time()\n        \n        crawler = FinalPOICrawler(CONFIG)\n        try:\n            crawler.process_addresses(addresses)\n            \n            elapsed = time.time() - start_time\n            print(f\"\\n🎉 全量爬取完成！\")\n            print(f\"⏱️ 总耗时: {elapsed/60:.1f} 分钟\")\n            print(f\"📈 平均速度: {elapsed/len(addresses):.1f} 秒/个\")\n            \n        except KeyboardInterrupt:\n            print(\"\\n⏹️ 用户中断爬取\")\n        except Exception as e:\n            print(f\"\\n❌ 爬取过程出错: {e}\")\n        finally:\n            crawler.close()\n    else:\n        print(\"❌ 已取消全量爬取\")\n        \nelse:\n    print(\"⏭️ 跳过全量爬取\")\n    print(\"💡 如需运行全量爬取，请将 RUN_FULL_CRAWL 设置为 True\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 5. 结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析爬取结果\n",
    "output_file = CONFIG['output_file']\n",
    "\n",
    "if Path(output_file).exists():\n",
    "    results = pd.read_csv(output_file)\n",
    "    \n",
    "    print(f\"📊 结果统计报告\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"📄 输出文件: {output_file}\")\n",
    "    print(f\"📈 总POI数量: {len(results):,}\")\n",
    "    print(f\"🏢 唯一建筑物: {results['blt_name'].nunique():,}\")\n",
    "    print(f\"⭐ 平均评分: {results['rating'].mean():.2f}\")\n",
    "    print(f\"💬 平均评论数: {results['review_count'].mean():.0f}\")\n",
    "    \n",
    "    print(f\"\\n📋 数据完整性分析:\")\n",
    "    completeness = {\n",
    "        '名称': results['name'].notna().sum(),\n",
    "        '评分': results['rating'].notna().sum(), \n",
    "        '评论数': results['review_count'].notna().sum(),\n",
    "        '类别': results['category'].notna().sum(),\n",
    "        '地址': results['address'].notna().sum(),\n",
    "        '电话': results['phone'].notna().sum(),\n",
    "        '网站': results['website'].notna().sum(),\n",
    "        '营业时间': results['hours'].notna().sum(),\n",
    "        '价格等级': results['price_level'].notna().sum()\n",
    "    }\n",
    "    \n",
    "    for field, count in completeness.items():\n",
    "        percentage = count / len(results) * 100\n",
    "        print(f\"  {field}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🏆 TOP 10 建筑物 (按POI数量):\")\n",
    "    top_buildings = results.groupby('blt_name').size().sort_values(ascending=False).head(10)\n",
    "    for i, (building, count) in enumerate(top_buildings.items(), 1):\n",
    "        print(f\"  {i:2d}. {building}: {count} 个POI\")\n",
    "    \n",
    "    print(f\"\\n⭐ 评分分布:\")\n",
    "    rating_dist = results['rating'].value_counts().sort_index()\n",
    "    for rating, count in rating_dist.head().items():\n",
    "        print(f\"  {rating}星: {count} 个POI\")\n",
    "    \n",
    "    print(f\"\\n📱 联系方式统计:\")\n",
    "    print(f\"  有电话号码: {results['phone'].notna().sum()} 个POI\")\n",
    "    print(f\"  有官方网站: {results['website'].notna().sum()} 个POI\")\n",
    "    \n",
    "    print(f\"\\n💰 价格等级分布:\")\n",
    "    if 'price_level' in results.columns:\n",
    "        price_dist = results['price_level'].value_counts().sort_index()\n",
    "        price_labels = {1: '$ (便宜)', 2: '$$ (中等)', 3: '$$$ (偏贵)', 4: '$$$$ (昂贵)'}\n",
    "        for level, count in price_dist.items():\n",
    "            label = price_labels.get(level, f'{level}级')\n",
    "            print(f\"  {label}: {count} 个POI\")\n",
    "    \n",
    "    print(f\"\\n📋 数据样例:\")\n",
    "    display(results.head())\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ 输出文件不存在: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 6. 数据导出和后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清理和导出\n",
    "if Path(output_file).exists():\n",
    "    results = pd.read_csv(output_file)\n",
    "    \n",
    "    print(f\"🔧 数据后处理...\")\n",
    "    \n",
    "    # 数据清理\n",
    "    cleaned_results = results.copy()\n",
    "    \n",
    "    # 移除重复POI\n",
    "    before_dedup = len(cleaned_results)\n",
    "    cleaned_results = cleaned_results.drop_duplicates(subset=['name', 'blt_name'], keep='first')\n",
    "    after_dedup = len(cleaned_results)\n",
    "    print(f\"  🗑️ 移除重复POI: {before_dedup - after_dedup} 个\")\n",
    "    \n",
    "    # 数据类型优化\n",
    "    if 'rating' in cleaned_results.columns:\n",
    "        cleaned_results['rating'] = pd.to_numeric(cleaned_results['rating'], errors='coerce')\n",
    "    if 'review_count' in cleaned_results.columns:\n",
    "        cleaned_results['review_count'] = pd.to_numeric(cleaned_results['review_count'], errors='coerce')\n",
    "    if 'price_level' in cleaned_results.columns:\n",
    "        cleaned_results['price_level'] = pd.to_numeric(cleaned_results['price_level'], errors='coerce')\n",
    "    \n",
    "    # 保存清理后的数据\n",
    "    clean_output_file = output_file.replace('.csv', '_清理版.csv')\n",
    "    cleaned_results.to_csv(clean_output_file, index=False, encoding='utf-8')\n",
    "    print(f\"  💾 清理版数据已保存: {clean_output_file}\")\n",
    "    \n",
    "    # 按建筑物分组导出\n",
    "    building_summary = cleaned_results.groupby('blt_name').agg({\n",
    "        'name': 'count',\n",
    "        'rating': 'mean',\n",
    "        'review_count': 'sum',\n",
    "        'category': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown'\n",
    "    }).round(2)\n",
    "    \n",
    "    building_summary.columns = ['POI数量', '平均评分', '总评论数', '主要类别']\n",
    "    building_summary = building_summary.sort_values('POI数量', ascending=False)\n",
    "    \n",
    "    summary_file = output_file.replace('.csv', '_建筑物汇总.csv')\n",
    "    building_summary.to_csv(summary_file, encoding='utf-8')\n",
    "    print(f\"  📊 建筑物汇总已保存: {summary_file}\")\n",
    "    \n",
    "    print(f\"\\n✅ 数据处理完成！\")\n",
    "    print(f\"📁 输出文件:\")\n",
    "    print(f\"  - 原始数据: {output_file}\")\n",
    "    print(f\"  - 清理版本: {clean_output_file}\")\n",
    "    print(f\"  - 建筑汇总: {summary_file}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ 没有找到结果文件进行后处理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 7. 检查点状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看检查点信息\n",
    "checkpoint_file = 'checkpoint.json'\n",
    "\n",
    "if Path(checkpoint_file).exists():\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "            checkpoint = json.load(f)\n",
    "        \n",
    "        print(f\"📋 检查点状态报告\")\n",
    "        print(f\"=\"*40)\n",
    "        print(f\"⏰ 最后更新: {checkpoint.get('timestamp', 'Unknown')}\")\n",
    "        print(f\"📊 已处理地址: {checkpoint.get('processed_count', 0):,}\")\n",
    "        print(f\"✅ 成功数量: {checkpoint.get('success_count', 0):,}\")\n",
    "        print(f\"❌ 失败数量: {len(checkpoint.get('failed_addresses', [])):,}\")\n",
    "        \n",
    "        if checkpoint.get('processed_count', 0) > 0:\n",
    "            success_rate = checkpoint.get('success_count', 0) / checkpoint.get('processed_count', 1) * 100\n",
    "            print(f\"📈 成功率: {success_rate:.1f}%\")\n",
    "        \n",
    "        failed_addresses = checkpoint.get('failed_addresses', [])\n",
    "        if failed_addresses:\n",
    "            print(f\"\\n❌ 失败地址样例 (前5个):\")\n",
    "            for i, addr in enumerate(failed_addresses[:5], 1):\n",
    "                print(f\"  {i}. {addr}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 读取检查点文件失败: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"ℹ️ 没有检查点文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🎯 v2.0 更新总结\n\n### 🚀 性能提升\n- **静默运行**: 完全屏蔽Chrome启动警告，纯净输出体验\n- **4倍并发**: 智能WebDriver池，同时处理4个地址\n- **内存优化**: 禁用图片、插件等，专注数据提取\n- **智能等待**: 替代固定延时，提高爬取效率\n\n### 📊 数据增强  \n- **9个字段**: name, rating, review_count, category, address, phone, website, hours, price_level\n- **元数据完整**: 建筑物名称、坐标、爬取时间等\n- **数据质量**: 支持多种POI类型，智能去重\n\n### 🛡️ 稳定可靠\n- **多策略定位**: 页面结构变化也能正常工作\n- **智能重试**: 自动处理临时网络错误\n- **断点续爬**: 支持大规模数据收集，意外中断可恢复\n- **错误容错**: 单个地址失败不影响整体进度\n\n### 🔧 易用性改进\n- **统一入口**: 一个程序包含所有功能\n- **智能文件选择**: 自动扫描并选择最大CSV文件\n- **测试模式**: 快速验证环境和配置\n- **详细进度**: 实时显示爬取进度和统计信息\n\n---\n**💡 提示**: \n- 首次使用建议先运行测试模式验证环境\n- 大规模爬取前建议小批量测试确认效果\n- 生成的CSV文件包含完整的9个数据字段\n- 程序支持中断后断点续爬，适合长时间运行",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokyo_poi_crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}