#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆPOIæ•°æ®æå–å™¨
åŒ…å«å®Œæ•´çš„POIä¿¡æ¯æå–åŠŸèƒ½ï¼Œä¸ä¾èµ–åŸå§‹info_tool.py
å¢åŠ äº†è¯„è®ºæ•°é‡ã€è¥ä¸šæ—¶é—´ã€ç”µè¯å·ç ç­‰æ›´å¤šæœ‰ç”¨ä¿¡æ¯
"""

from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import logging

logger = logging.getLogger(__name__)

class EnhancedPOIExtractor:
    """å¢å¼ºç‰ˆPOIæ•°æ®æå–å™¨"""
    
    def __init__(self):
        self.building_keywords = [
            'å»ºç­‘ç‰©', 'å»ºç¯‰ç‰©', 'å»ºé€ ç‰©', 'building',
            'ãƒ“ãƒ«', 'ãƒãƒ³ã‚·ãƒ§ãƒ³', 'ã‚¢ãƒ‘ãƒ¼ãƒˆ', 
            'ä½å®…', 'äº‹å‹™æ‰€', 'ã‚ªãƒ•ã‚£ã‚¹',
            'å•†æ¥­æ–½è¨­', 'åº—èˆ—', 'è¤‡åˆæ–½è¨­'
        ]
    
    def get_coords(self, url):
        """ä»URLä¸­æå–åæ ‡"""
        try:
            target_substring = "/@"
            start_index = url.find(target_substring)
            
            if start_index != -1:
                # æå–åæ ‡éƒ¨åˆ†
                coord_part = url[start_index + len(target_substring):]
                coords = coord_part.split(',')
                
                if len(coords) >= 2:
                    lat = float(coords[0])
                    lng = float(coords[1])
                    return lat, lng
        except Exception as e:
            logger.warning(f"åæ ‡æå–å¤±è´¥: {e}")
        
        return None, None
    
    def get_building_type_robust(self, driver, timeout=10):
        """è·å–åœ°ç‚¹ç±»å‹ - å¤šç­–ç•¥ç‰ˆæœ¬"""
        strategies = [
            # ç­–ç•¥1: é€šç”¨æ ·å¼é€‰æ‹©å™¨
            {
                'method': 'css',
                'selector': 'span[class*="fontBodyMedium"]',
                'description': 'é€šç”¨å­—ä½“æ ·å¼é€‰æ‹©å™¨'
            },
            # ç­–ç•¥2: é€šç”¨spané€‰æ‹©å™¨
            {
                'method': 'xpath',
                'selector': '//span[contains(@class, "fontBodyMedium") or contains(@class, "place-type")]',
                'description': 'é€šç”¨spané€‰æ‹©å™¨'
            },
            # ç­–ç•¥3: åŸå§‹XPATHï¼ˆå¤‡ç”¨ï¼‰
            {
                'method': 'xpath',
                'selector': '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[2]/span/span/span',
                'description': 'åŸå§‹XPATH'
            }
        ]
        
        for strategy in strategies:
            try:
                if strategy['method'] == 'css':
                    element = WebDriverWait(driver, timeout).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, strategy['selector']))
                    )
                else:
                    element = WebDriverWait(driver, timeout).until(
                        EC.presence_of_element_located((By.XPATH, strategy['selector']))
                    )
                
                place_type = element.text.strip()
                if place_type and place_type.lower() not in ['', 'loading', 'èª­ã¿è¾¼ã¿ä¸­']:
                    return place_type
                    
            except Exception:
                continue
        
        return None
    
    def is_building(self, place_type):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå»ºç­‘ç‰©ç±»å‹"""
        if not place_type:
            return False
        
        place_type_lower = place_type.lower()
        
        for keyword in self.building_keywords:
            if keyword.lower() in place_type_lower:
                return True
        
        return False
    
    def get_building_name(self, driver, timeout=15):
        """è·å–å»ºç­‘ç‰©åç§°"""
        name_selectors = [
            '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[1]/h1',
            'h1[data-attrid="title"]',
            '.x3AX1-LfntMc-header-title-title',
            'h1'
        ]
        
        for selector in name_selectors:
            try:
                if selector.startswith('/'):
                    element = WebDriverWait(driver, timeout).until(
                        EC.presence_of_element_located((By.XPATH, selector))
                    )
                else:
                    element = WebDriverWait(driver, timeout).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                    )
                
                place_name = element.text.strip()
                if place_name:
                    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
                    place_name = re.sub(r'[/|ï½œ*!?:]', ' ', place_name)
                    return place_name
                    
            except Exception:
                continue
        
        return "æœªçŸ¥å»ºç­‘"
    
    def get_poi_count(self, driver):
        """è·å–POIæ€»æ•°"""
        try:
            count_elements = driver.find_elements(By.XPATH, "//span[@class='bC3Nkc fontBodySmall']")
            if count_elements:
                total = sum(int(elem.text) for elem in count_elements if elem.text.isdigit())
                return total
        except Exception:
            pass
        
        return 0
    
    def extract_poi_info(self, soup):
        """ä»BeautifulSoupå¯¹è±¡ä¸­æå–POIä¿¡æ¯"""
        poi_data = {
            'name': 'Unknown',
            'rating': None,
            'review_count': 0,
            'category': 'Unknown',
            'address': 'Unknown',
            'phone': None,
            'website': None,
            'hours': None,
            'price_level': None
        }
        
        try:
            # æå–POIåç§°
            name_elem = soup.find('div', class_='qBF1Pd fontHeadlineSmall')
            if name_elem:
                poi_data['name'] = name_elem.text.strip()
        except:
            pass
        
        try:
            # æå–è¯„åˆ†
            rating_elem = soup.find("span", class_='MW4etd')
            if rating_elem:
                rating_text = rating_elem.text.strip()
                rating_match = re.search(r'(\d+\.?\d*)', rating_text)
                if rating_match:
                    poi_data['rating'] = float(rating_match.group(1))
        except:
            pass
        
        try:
            # æå–è¯„è®ºæ•°é‡
            review_elem = soup.find("span", class_='UY7F9')
            if review_elem:
                review_text = review_elem.text
                review_match = re.search(r'(\d+)', review_text.replace(',', ''))
                if review_match:
                    poi_data['review_count'] = int(review_match.group(1))
        except:
            pass
        
        try:
            # æå–ç±»åˆ«å’Œåœ°å€
            info_divs = soup.find_all("div", {"class": 'W4Efsd'})
            if len(info_divs) > 2:
                spans = info_divs[2].select("span")
                if len(spans) > 1:
                    poi_data['category'] = spans[1].text.strip()
                if len(spans) > 4:
                    poi_data['address'] = spans[4].text.strip()
        except:
            pass
        
        try:
            # æå–ç”µè¯å·ç 
            phone_elem = soup.find('button', {'data-item-id': 'phone:tel'})
            if phone_elem:
                poi_data['phone'] = phone_elem.get('aria-label', '').replace('ç”µè¯å·ç : ', '')
        except:
            pass
        
        try:
            # æå–ç½‘ç«™
            website_elem = soup.find('a', {'data-item-id': 'authority'})
            if website_elem:
                poi_data['website'] = website_elem.get('href', '')
        except:
            pass
        
        try:
            # æå–è¥ä¸šæ—¶é—´
            hours_elem = soup.find('div', class_='t39EBf GUrTXd')
            if hours_elem:
                poi_data['hours'] = hours_elem.text.strip()
        except:
            pass
        
        try:
            # æå–ä»·æ ¼ç­‰çº§ ($ $$ $$$ $$$$)
            price_elem = soup.find('span', class_='mgr77e')
            if price_elem:
                price_text = price_elem.text
                price_count = price_text.count('$') + price_text.count('Â¥')
                if price_count > 0:
                    poi_data['price_level'] = price_count
        except:
            pass
        
        return poi_data
    
    def get_all_poi_info_enhanced(self, driver):
        """è·å–æ‰€æœ‰POIä¿¡æ¯ - å¢å¼ºç‰ˆ"""
        poi_list = []
        
        # å¤šç§POIå®¹å™¨classå°è¯•
        poi_container_classes = [
            "Nv2PK.THOPZb.CpccDe", 
            'Nv2PK.Q2HXcd.THOPZb',
            'Nv2PK THOPZb CpccDe',
            'lI9IFe'  # æ–°çš„å¯èƒ½class
        ]
        
        print('ğŸ” æ­£åœ¨æå–POIä¿¡æ¯...')
        
        for container_class in poi_container_classes:
            try:
                poi_elements = driver.find_elements(By.CLASS_NAME, container_class.replace(' ', '.'))
                
                if poi_elements:
                    print(f"  âœ… æ‰¾åˆ° {len(poi_elements)} ä¸ªPOIå…ƒç´  (ä½¿ç”¨class: {container_class})")
                    
                    for poi_element in poi_elements:
                        try:
                            soup = BeautifulSoup(poi_element.get_attribute('innerHTML'), "html.parser")
                            poi_info = self.extract_poi_info(soup)
                            
                            # åªæ·»åŠ æœ‰æ•ˆçš„POIä¿¡æ¯
                            if poi_info['name'] != 'Unknown':
                                poi_list.append(poi_info)
                        except Exception as e:
                            logger.warning(f"æå–å•ä¸ªPOIå¤±è´¥: {e}")
                            continue
                    
                    break  # æ‰¾åˆ°æ•°æ®å°±åœæ­¢å°è¯•å…¶ä»–class
                    
            except Exception as e:
                logger.warning(f"å°è¯•class {container_class} å¤±è´¥: {e}")
                continue
        
        if poi_list:
            df = pd.DataFrame(poi_list)
            print(f"  âœ… æˆåŠŸæå– {len(df)} ä¸ªPOIä¿¡æ¯")
            return df
        else:
            print("  âŒ æœªæ‰¾åˆ°POIä¿¡æ¯")
            # è¿”å›ç©ºDataFrameä½†åŒ…å«æ‰€æœ‰åˆ—
            return pd.DataFrame(columns=[
                'name', 'rating', 'review_count', 'category', 'address', 
                'phone', 'website', 'hours', 'price_level'
            ])

# ä¸ºäº†å‘åå…¼å®¹ï¼Œæä¾›ç‹¬ç«‹å‡½æ•°
def get_building_type_robust(driver, timeout=10):
    """å‘åå…¼å®¹çš„å‡½æ•°"""
    extractor = EnhancedPOIExtractor()
    return extractor.get_building_type_robust(driver, timeout)

def is_building(place_type):
    """å‘åå…¼å®¹çš„å‡½æ•°"""
    extractor = EnhancedPOIExtractor()
    return extractor.is_building(place_type)

def safe_get_building_name(driver, timeout=15):
    """å‘åå…¼å®¹çš„å‡½æ•°"""
    extractor = EnhancedPOIExtractor()
    return extractor.get_building_name(driver, timeout)

def safe_get_coords(url):
    """å‘åå…¼å®¹çš„å‡½æ•°"""
    extractor = EnhancedPOIExtractor()
    return extractor.get_coords(url)

def safe_get_all_poi_info(driver):
    """å‘åå…¼å®¹çš„å‡½æ•°"""
    extractor = EnhancedPOIExtractor()
    return extractor.get_all_poi_info_enhanced(driver)

print("âœ… å¢å¼ºç‰ˆPOIæå–å™¨åŠ è½½å®Œæˆ")