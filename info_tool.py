from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from bs4 import BeautifulSoup
import time
import pandas as pd

def wait_for_coords_url(driver, timeout=5):
    """ç­‰å¾…è·³è½¬åçš„ Google Maps URL å‡ºç° /@lat,lng æ ¼å¼"""
    try:
        WebDriverWait(driver, timeout).until(lambda d: "/@" in d.current_url)
        return driver.current_url
    except Exception as e:
        print("ç­‰å¾…è·³è½¬å¤±è´¥ï¼š", e)
        return None



def has_hotel_category(driver, address):
    """æ£€æŸ¥æ˜¯å¦æ˜¯é…’åº—ç±»åˆ«é¡µé¢"""
    try:
        # æ£€æŸ¥é…’åº—ç±»åˆ«æ ‡é¢˜
        selectors = [
            "h2.kPvgOb.fontHeadlineSmall",
            "div.aIiAFe h1",
            "h1.jRccSf",
            "h1.ZoUhNb"
        ]
        
        for selector in selectors:
            try:
                elements = driver.find_elements("css selector", selector)
                for element in elements:
                    text = element.text.strip().lower()
                    if any(keyword in text for keyword in ["é…’åº—", "ãƒ›ãƒ†ãƒ«", "hotel", "lodging", "accommodation"]):
                       
                        print(f"ğŸ¨ æ£€æµ‹åˆ°é…’åº—é¡µé¢: {text} | {address[:30]}...")
                        return True
            except:
                continue
                
        return False
    except:
        return False

def get_coords(http_url):
    target_substring = "/@"
    start_index = http_url.find(target_substring)

    if start_index != -1:
        end_index = http_url.find('/', start_index + 2)  # æ‰¾åˆ° `/@.../` çš„ç»“å°¾
        if end_index == -1:
            end_index = len(http_url)
        extracted = http_url[start_index + 2 : end_index]
        parts = extracted.split(',')
        if len(parts) >= 2:
            lat = float(parts[0])
            lng = float(parts[1])
            return lat, lng
    return None, None



#åˆ¤æ–­æ˜¯å¦æ˜¯å»ºç­‘ç‰©
def get_building_type(driver):
    try:
        place_type_XPATH = '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[2]/span/span/span'
        # æ¢å¤å……è¶³ç­‰å¾…æ—¶é—´ç¡®ä¿å…ƒç´ åŠ è½½å®Œæˆ
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, place_type_XPATH)))
        place_type = driver.find_element(By.XPATH, place_type_XPATH).text
    except:
        place_type = 'nan'
  
    return place_type



# å–å¾—poiåç¨±
def get_building_name(driver):
    # å›åˆ°è€ç‰ˆæœ¬ç®€å•å¯é çš„ç­–ç•¥
    place_name_XPATH = '//*[@id="QA0Szd"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[1]/h1'
    xpath_candidates = [
        (place_name_XPATH, 10),  # ä¸»è¦XPathï¼Œä½¿ç”¨è€ç‰ˆæœ¬çš„å……è¶³ç­‰å¾…æ—¶é—´
        ('//h1[@data-value]', 5),
        ('//h1[contains(@class, "x3AX1")]', 5),
        ('//div[@data-value]//h1', 3),
        ('//span[@data-value]', 3)
    ]
    
    for xpath, timeout in xpath_candidates:
        try:
            WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.XPATH, xpath)))
            place_name = driver.find_element(By.XPATH, xpath).text
            if place_name and place_name.strip():
                # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
                place_name = place_name.replace('/', ' ')
                place_name = place_name.replace('|', ' ')
                place_name = place_name.replace('ï½œ', ' ')
                place_name = place_name.replace('*', ' ')
                place_name = place_name.replace('!', ' ')
                place_name = place_name.replace('?', ' ')
                place_name = place_name.replace(':', ' ')
                return place_name.strip()
        except:
            continue
    
    # å¦‚æœæ‰€æœ‰XPathéƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†
    raise Exception("æ— æ³•æ‰¾åˆ°åœ°ç‚¹åç§°")

#è·å¾—å·²çŸ¥poiæ€»æ•°
def get_poi_type_total(driver):
  
    user_ratings_list = [poitype.text for poitype in driver.find_elements(By.XPATH, "//span[@class='bC3Nkc fontBodySmall']")]

    user_ratings_total_element = sum(int(num) for num in user_ratings_list)

    return user_ratings_total_element
    


def get_poi_comment_count(driver):
    try:
        comment_elements = driver.find_elements(By.XPATH, "//span[@class='bC3Nkc fontBodySmall']")
        if comment_elements:
            return sum(int(elem.text) for elem in comment_elements if elem.text.isdigit())
        return 0
    except:
        return 0


def get_all_poi_info(driver):
    
    result = {}
    poi_name_list = []
    poi_rating_list = []
    poi_class_list = []
    poi_add_list = []
    poi_comment_list = []

    
        
    ele_class_list = ["Nv2PK.THOPZb.CpccDe", 'Nv2PK.Q2HXcd.THOPZb']
    for class_key in ele_class_list:
   
        poi_frame_list = driver.find_elements(By.CSS_SELECTOR, f"div.{class_key.replace('.', '.')}")

        if poi_frame_list:

            for poi_frame in poi_frame_list:
                soup = BeautifulSoup(poi_frame.get_attribute('innerHTML'), "html.parser") 
                
                poi_name = get_poi_name(soup)  # å–å¾— user åç¨± 
                #user_profile_url = get_user_profile_url(soup)  # å–å¾— user å€‹äººæª”æ¡ˆçš„ URL
                rating = get_rating(soup)  # å–å¾—è©•ç´š
                poi_class, poi_address = get_class_address(soup)
                poi_comment_count = get_rating_count(soup)  # å–å¾—å–®å€‹POIè©•è«–æ•¸
                #local_guide, comment_num = get_local_guide_and_comment_num(soup)  # å–å¾—åœ¨åœ°åš®å°çš„ç‹€æ…‹å’Œè©•è«–æ•¸
                #comment_text = get_comment_text(soup)# å–å¾—è©•è«–å…§æ–‡
                poi_name_list.append(poi_name)
                poi_rating_list.append(rating)
                poi_class_list.append(poi_class)
                poi_add_list.append(poi_address)
                poi_comment_list.append(poi_comment_count)
        else:
            continue
    
 
    if len(poi_name_list) > 0:
       df = pd.DataFrame(
                        {'name': poi_name_list, 
                         'rating': poi_rating_list,	
                         'class' : poi_class_list,	
                         'add' : poi_add_list,
                         'comment_count': poi_comment_list
                        })
    else:
        df = None
        
    return df
            


# å–å¾— poi åç¨±
def get_poi_name(soup):
    poi_name = soup.find('div', class_ = 'qBF1Pd fontHeadlineSmall').text

    return poi_name
    

# å–å¾—è©•ç´š
def get_rating(soup):
    try:
        rating = soup.find("span", class_='MW4etd').text
        
    except:
        rating = 'nan'
        
    return rating



def get_rating_count(soup):
    try:
        rating_count = soup.find("span", class_='UY7F9').text
        rating_count = int(rating_count.strip("()"))
    
    except:
        rating_count = 'nan'
        
    return rating_count




# å–å¾—åˆ†ç±»
def get_class_address(soup):

    
    class_div = soup.find_all("div",{"class":'W4Efsd'})
    
    try:
        class_list = class_div[2].select("span")[1].text
    except:
        class_list='nan'
    try:
        add_list=class_div[2].select("span")[4].text
    except:
        add_list='nan'
        
    
    return class_list,add_list






