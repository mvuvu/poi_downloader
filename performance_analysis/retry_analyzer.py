
import re
from collections import Counter
from pathlib import Path
import json

def analyze_retry_patterns(log_file):
    """åˆ†æžé‡è¯•ä»»åŠ¡æ¨¡å¼"""
    
    retry_addresses = []
    normal_addresses = []
    retry_pattern = r'ðŸ”„ éžå»ºç­‘ç‰©ï¼Œä½¿ç”¨æ—¥æ–‡åœ°å€é‡è¯•: (.+)'
    success_pattern = r'âœ… (.+) \| POI: (\d+) \| çŠ¶æ€: å·²ä¿å­˜'
    
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            # æ”¶é›†é‡è¯•åœ°å€
            retry_match = re.search(retry_pattern, line)
            if retry_match:
                retry_addresses.append(retry_match.group(1))
            
            # æ”¶é›†æˆåŠŸåœ°å€
            success_match = re.search(success_pattern, line)
            if success_match:
                normal_addresses.append(success_match.group(1))
    
    # åˆ†æž
    total_tasks = len(normal_addresses) + len(retry_addresses)
    retry_rate = len(retry_addresses) / total_tasks * 100 if total_tasks > 0 else 0
    
    print(f"\nðŸ“Š é‡è¯•ä»»åŠ¡åˆ†æž:")
    print(f"  æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print(f"  é‡è¯•ä»»åŠ¡æ•°: {len(retry_addresses)}")
    print(f"  é‡è¯•çŽ‡: {retry_rate:.1f}%")
    
    # åˆ†æžé‡è¯•åœ°å€ç‰¹å¾
    if retry_addresses:
        print(f"\nðŸ” é‡è¯•åœ°å€ç¤ºä¾‹:")
        for addr in retry_addresses[:5]:
            print(f"  - {addr}")
    
    # ä¿å­˜åˆ†æžç»“æžœ
    results = {
        'total_tasks': total_tasks,
        'retry_count': len(retry_addresses),
        'retry_rate': retry_rate,
        'retry_addresses_sample': retry_addresses[:20]
    }
    
    with open('performance_analysis/retry_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return results

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        analyze_retry_patterns(sys.argv[1])
    else:
        print("ä½¿ç”¨æ–¹æ³•: python retry_analyzer.py crawler_output.log")
