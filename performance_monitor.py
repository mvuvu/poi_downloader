#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ç›‘æ§è„šæœ¬ - ç”¨äºåˆ†æPOIçˆ¬è™«è¿è¡Œæ—¶çš„æ€§èƒ½é—®é¢˜
"""

import time
import threading
import psutil
import pandas as pd
from datetime import datetime
import json
import os
from pathlib import Path
import subprocess
import argparse

class PerformanceMonitor:
    """POIçˆ¬è™«æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, output_dir="performance_logs", interval=30):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.interval = interval  # ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
        self.start_time = time.time()
        self.monitoring = False
        self.monitor_thread = None
        
        # æ€§èƒ½æ•°æ®
        self.performance_data = []
        self.task_stats = []
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.perf_log = self.output_dir / f"performance_{timestamp}.csv"
        self.task_log = self.output_dir / f"task_stats_{timestamp}.json"
        
    def start(self):
        """å¯åŠ¨ç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        print(f"ğŸš€ æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ï¼Œæ•°æ®å°†ä¿å­˜åˆ°: {self.output_dir}")
        
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        self._save_data()
        print(f"ğŸ“Š æ€§èƒ½ç›‘æ§å·²åœæ­¢ï¼Œæ•°æ®å·²ä¿å­˜")
        
    def _monitor_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        while self.monitoring:
            try:
                # æ”¶é›†ç³»ç»Ÿæ€§èƒ½æ•°æ®
                perf_data = self._collect_performance_data()
                self.performance_data.append(perf_data)
                
                # æ”¶é›†ä»»åŠ¡ç»Ÿè®¡æ•°æ®
                task_data = self._collect_task_stats()
                if task_data:
                    self.task_stats.append(task_data)
                
                # å®æ—¶è¾“å‡ºå…³é”®æŒ‡æ ‡
                self._print_realtime_stats(perf_data, task_data)
                
                # å®šæœŸä¿å­˜æ•°æ®
                if len(self.performance_data) % 10 == 0:
                    self._save_data()
                
                time.sleep(self.interval)
                
            except Exception as e:
                print(f"âŒ ç›‘æ§é”™è¯¯: {e}")
                
    def _collect_performance_data(self):
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æ•°æ®"""
        # è·å–POIçˆ¬è™«è¿›ç¨‹
        crawler_processes = []
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if 'poi_crawler_simple.py' in ' '.join(proc.info['cmdline'] or []):
                    crawler_processes.append(proc)
            except:
                continue
        
        # æ”¶é›†æ•°æ®
        data = {
            'timestamp': datetime.now().isoformat(),
            'elapsed_time': time.time() - self.start_time,
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'memory_used_gb': psutil.virtual_memory().used / (1024**3),
            'crawler_count': len(crawler_processes),
            'crawler_cpu': 0,
            'crawler_memory_mb': 0,
            'chrome_processes': 0,
            'chrome_memory_mb': 0
        }
        
        # çˆ¬è™«è¿›ç¨‹ç»Ÿè®¡
        for proc in crawler_processes:
            try:
                data['crawler_cpu'] += proc.cpu_percent()
                data['crawler_memory_mb'] += proc.memory_info().rss / (1024**2)
            except:
                pass
        
        # Chromeè¿›ç¨‹ç»Ÿè®¡
        for proc in psutil.process_iter(['name', 'memory_info']):
            try:
                if 'chrome' in proc.info['name'].lower():
                    data['chrome_processes'] += 1
                    data['chrome_memory_mb'] += proc.memory_info().rss / (1024**2)
            except:
                pass
        
        return data
        
    def _collect_task_stats(self):
        """æ”¶é›†ä»»åŠ¡ç»Ÿè®¡æ•°æ®ï¼ˆä»è¿›åº¦æ–‡ä»¶è¯»å–ï¼‰"""
        progress_dir = Path("data/progress")
        if not progress_dir.exists():
            return None
            
        stats = {
            'timestamp': datetime.now().isoformat(),
            'files': []
        }
        
        # è¯»å–æ‰€æœ‰è¿›åº¦æ–‡ä»¶
        for progress_file in progress_dir.glob("*_simple_progress.json"):
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                    
                # è®¡ç®—ä»»åŠ¡é€Ÿåº¦
                if 'last_updated' in progress and 'timestamp' in progress:
                    duration = progress['last_updated'] - progress['timestamp']
                    speed = progress['processed_tasks'] / duration if duration > 0 else 0
                else:
                    speed = 0
                    
                file_stats = {
                    'file_name': progress['file_name'],
                    'total_tasks': progress.get('total_tasks', 0),
                    'processed_tasks': progress.get('processed_tasks', 0),
                    'success_count': progress.get('success_count', 0),
                    'error_count': progress.get('error_count', 0),
                    'progress_percent': (progress['processed_tasks'] / progress['total_tasks'] * 100) if progress.get('total_tasks', 0) > 0 else 0,
                    'success_rate': (progress['success_count'] / progress['processed_tasks'] * 100) if progress.get('processed_tasks', 0) > 0 else 0,
                    'speed_per_second': speed
                }
                stats['files'].append(file_stats)
                
            except Exception as e:
                continue
                
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        if stats['files']:
            stats['total_processed'] = sum(f['processed_tasks'] for f in stats['files'])
            stats['total_success'] = sum(f['success_count'] for f in stats['files'])
            stats['total_errors'] = sum(f['error_count'] for f in stats['files'])
            stats['avg_success_rate'] = (stats['total_success'] / stats['total_processed'] * 100) if stats['total_processed'] > 0 else 0
            stats['avg_speed'] = sum(f['speed_per_second'] for f in stats['files']) / len(stats['files'])
        
        return stats
        
    def _print_realtime_stats(self, perf_data, task_data):
        """æ‰“å°å®æ—¶ç»Ÿè®¡ä¿¡æ¯"""
        elapsed_min = perf_data['elapsed_time'] / 60
        
        print(f"\nâ±ï¸  è¿è¡Œæ—¶é—´: {elapsed_min:.1f} åˆ†é’Ÿ")
        print(f"ğŸ’» ç³»ç»ŸçŠ¶æ€: CPU {perf_data['cpu_percent']:.1f}% | å†…å­˜ {perf_data['memory_percent']:.1f}% ({perf_data['memory_used_gb']:.1f}GB)")
        print(f"ğŸ•·ï¸  çˆ¬è™«è¿›ç¨‹: {perf_data['crawler_count']} ä¸ª | CPU {perf_data['crawler_cpu']:.1f}% | å†…å­˜ {perf_data['crawler_memory_mb']:.0f}MB")
        print(f"ğŸŒ Chromeè¿›ç¨‹: {perf_data['chrome_processes']} ä¸ª | å†…å­˜ {perf_data['chrome_memory_mb']:.0f}MB")
        
        if task_data and 'total_processed' in task_data:
            print(f"ğŸ“Š ä»»åŠ¡ç»Ÿè®¡: å·²å¤„ç† {task_data['total_processed']} | æˆåŠŸç‡ {task_data['avg_success_rate']:.1f}% | é€Ÿåº¦ {task_data['avg_speed']:.2f}/ç§’")
            
            # æ£€æµ‹æ€§èƒ½ä¸‹é™
            if elapsed_min > 30:  # è¿è¡Œè¶…è¿‡30åˆ†é’Ÿåå¼€å§‹æ£€æµ‹
                if perf_data['cpu_percent'] < 20 and perf_data['crawler_cpu'] < 50:
                    print("âš ï¸  è­¦å‘Š: CPUåˆ©ç”¨ç‡è¿‡ä½ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ")
                if task_data['avg_speed'] < 0.1:  # æ¯ç§’å¤„ç†å°‘äº0.1ä¸ªä»»åŠ¡
                    print("âš ï¸  è­¦å‘Š: ä»»åŠ¡å¤„ç†é€Ÿåº¦è¿‡æ…¢")
                    
    def _save_data(self):
        """ä¿å­˜ç›‘æ§æ•°æ®"""
        # ä¿å­˜æ€§èƒ½æ•°æ®
        if self.performance_data:
            df = pd.DataFrame(self.performance_data)
            df.to_csv(self.perf_log, index=False)
            
        # ä¿å­˜ä»»åŠ¡ç»Ÿè®¡
        if self.task_stats:
            with open(self.task_log, 'w', encoding='utf-8') as f:
                json.dump(self.task_stats, f, ensure_ascii=False, indent=2)
                
    def analyze_performance_degradation(self):
        """åˆ†ææ€§èƒ½ä¸‹é™åŸå› """
        if not self.performance_data:
            print("âŒ æ²¡æœ‰è¶³å¤Ÿçš„æ€§èƒ½æ•°æ®è¿›è¡Œåˆ†æ")
            return
            
        df = pd.DataFrame(self.performance_data)
        
        print("\nğŸ“ˆ æ€§èƒ½è¶‹åŠ¿åˆ†æ:")
        
        # CPUä½¿ç”¨ç‡è¶‹åŠ¿
        cpu_start = df['crawler_cpu'].iloc[:10].mean()
        cpu_end = df['crawler_cpu'].iloc[-10:].mean()
        cpu_change = ((cpu_end - cpu_start) / cpu_start * 100) if cpu_start > 0 else 0
        print(f"   CPUä½¿ç”¨ç‡: {cpu_start:.1f}% â†’ {cpu_end:.1f}% (å˜åŒ–: {cpu_change:+.1f}%)")
        
        # å†…å­˜ä½¿ç”¨è¶‹åŠ¿
        mem_start = df['crawler_memory_mb'].iloc[:10].mean()
        mem_end = df['crawler_memory_mb'].iloc[-10:].mean()
        mem_change = ((mem_end - mem_start) / mem_start * 100) if mem_start > 0 else 0
        print(f"   å†…å­˜ä½¿ç”¨: {mem_start:.0f}MB â†’ {mem_end:.0f}MB (å˜åŒ–: {mem_change:+.1f}%)")
        
        # Chromeè¿›ç¨‹æ•°è¶‹åŠ¿
        chrome_start = df['chrome_processes'].iloc[:10].mean()
        chrome_end = df['chrome_processes'].iloc[-10:].mean()
        print(f"   Chromeè¿›ç¨‹æ•°: {chrome_start:.0f} â†’ {chrome_end:.0f}")
        
        # ä»»åŠ¡å¤„ç†é€Ÿåº¦åˆ†æ
        if self.task_stats and len(self.task_stats) > 10:
            speeds = [s.get('avg_speed', 0) for s in self.task_stats]
            speed_start = sum(speeds[:5]) / 5
            speed_end = sum(speeds[-5:]) / 5
            speed_change = ((speed_end - speed_start) / speed_start * 100) if speed_start > 0 else 0
            print(f"   å¤„ç†é€Ÿåº¦: {speed_start:.2f}/ç§’ â†’ {speed_end:.2f}/ç§’ (å˜åŒ–: {speed_change:+.1f}%)")
            
            # åˆ†æé‡è¯•ä»»åŠ¡å æ¯”ï¼ˆéœ€è¦é¢å¤–æ•°æ®æ”¯æŒï¼‰
            print("\nğŸ” å¯èƒ½çš„åŸå› :")
            if cpu_change < -50:
                print("   - CPUä½¿ç”¨ç‡å¤§å¹…ä¸‹é™ï¼Œå¯èƒ½æ˜¯ä»»åŠ¡é˜Ÿåˆ—æ¯ç«­æˆ–ç­‰å¾…æ—¶é—´è¿‡é•¿")
            if speed_change < -50:
                print("   - å¤„ç†é€Ÿåº¦æ˜¾è‘—ä¸‹é™ï¼Œå¯èƒ½æ˜¯é‡åˆ°å¤æ‚ä»»åŠ¡æˆ–é‡è¯•ä»»åŠ¡å¢å¤š")
            if mem_change > 100:
                print("   - å†…å­˜ä½¿ç”¨å¤§å¹…å¢åŠ ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼")
            if chrome_end > chrome_start * 1.5:
                print("   - Chromeè¿›ç¨‹æ•°å¢åŠ ï¼Œå¯èƒ½æ˜¯è¿›ç¨‹æ¸…ç†ä¸åŠæ—¶")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='POIçˆ¬è™«æ€§èƒ½ç›‘æ§å·¥å…·')
    parser.add_argument('--interval', type=int, default=30, help='ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('--analyze', action='store_true', help='åˆ†æå·²æœ‰çš„æ€§èƒ½æ•°æ®')
    parser.add_argument('--output', default='performance_logs', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    monitor = PerformanceMonitor(output_dir=args.output, interval=args.interval)
    
    if args.analyze:
        # åŠ è½½å¹¶åˆ†æå·²æœ‰æ•°æ®
        print("ğŸ“Š æ­£åœ¨åˆ†ææ€§èƒ½æ•°æ®...")
        # è¿™é‡Œéœ€è¦å®ç°åŠ è½½å·²æœ‰æ•°æ®çš„é€»è¾‘
        monitor.analyze_performance_degradation()
    else:
        # å®æ—¶ç›‘æ§
        try:
            monitor.start()
            print("ğŸ¯ æ€§èƒ½ç›‘æ§è¿è¡Œä¸­... æŒ‰ Ctrl+C åœæ­¢")
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ­£åœ¨åœæ­¢ç›‘æ§...")
            monitor.stop()
            monitor.analyze_performance_degradation()


if __name__ == "__main__":
    main()