#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import threading
import queue
import json
import pandas as pd
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import WebDriverException, TimeoutException
import os
import gc
import argparse
import glob
import signal
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# å¯¼å…¥ç°æœ‰çš„POIæå–å‡½æ•°
from info_tool import get_building_type, get_building_name, get_all_poi_info, get_coords, wait_for_coords_url, has_hotel_category
from driver_action import click_on_more_button, scroll_poi_section


class ChromeWorker(threading.Thread):
    """æŒä¹…åŒ–Chromeå·¥ä½œçº¿ç¨‹"""
    
    def __init__(self, worker_id, task_queue, result_queue, stop_event, verbose=False, retry_queue=None):
        super().__init__(daemon=True)
        self.worker_id = worker_id
        self.task_queue = task_queue
        self.result_queue = result_queue
        self.stop_event = stop_event
        self.verbose = verbose
        self.retry_queue = retry_queue  # é‡è¯•é˜Ÿåˆ—
        self.driver = None
        self.processed_count = 0
        self.success_count = 0
        self.error_count = 0
        
    def create_driver(self):
        """åˆ›å»ºä¼˜åŒ–çš„Chromeé©±åŠ¨ - åŸºäºturboç‰ˆæœ¬éªŒè¯é…ç½®"""
        try:
            options = webdriver.ChromeOptions()
        
            # åŸºç¡€é™é»˜é…ç½®
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--disable-software-rasterizer')
            
            # å½»åº•ç¦ç”¨æ—¥å¿—å’Œè­¦å‘Š
            options.add_argument('--log-level=3')
            options.add_argument('--silent')
            options.add_argument('--disable-logging')
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-plugins')
            options.add_argument('--disable-images')
            options.add_argument('--disable-javascript')
            options.add_argument('--disable-web-security')
            options.add_argument('--disable-features=VizDisplayCompositor')
            
            # GPUå’ŒWebGLé”™è¯¯æŠ‘åˆ¶
            options.add_argument('--disable-gl-error-limit')
            options.add_argument('--disable-webgl')
            options.add_argument('--disable-webgl2')
            options.add_argument('--use-gl=disabled')
            
            # DevToolså’Œè°ƒè¯•ä¿¡æ¯ç¦ç”¨
            options.add_argument('--remote-debugging-port=0')
            options.add_argument('--disable-background-timer-throttling')
            options.add_argument('--disable-backgrounding-occluded-windows')
            options.add_argument('--disable-renderer-backgrounding')
            
            # å®éªŒæ€§é€‰é¡¹
            options.add_experimental_option('excludeSwitches', ['enable-logging', 'enable-automation'])
            options.add_experimental_option('useAutomationExtension', False)
            
            # ç¦ç”¨è¯­éŸ³è¯†åˆ«å’ŒAIåŠŸèƒ½ï¼Œé¿å…TensorFlowåŠ è½½
            options.add_argument('--disable-speech-api')
            options.add_argument('--disable-features=AudioServiceOutOfProcess,TranslateUI')
            options.add_argument('--disable-background-media-suspend')
            options.add_experimental_option('prefs', {
                'profile.default_content_setting_values.media_stream_mic': 2,
                'profile.default_content_setting_values.media_stream_camera': 2,
                'profile.default_content_setting_values.geolocation': 2,
                'profile.default_content_setting_values.notifications': 2
            })
        
            # å®Œå…¨é™é»˜Service
            service = Service(
                ChromeDriverManager().install(),
                log_path='NUL',
                service_args=['--silent']
            )
            
            driver = webdriver.Chrome(service=service, options=options)
            
            # æµ‹è¯•ç©ºé¡µé¢åŠ è½½
            driver.get('about:blank')
            
            if self.verbose:
                print(f"âœ… Worker {self.worker_id}: Chromeé©±åŠ¨åˆ›å»ºæˆåŠŸ")
            
            return driver
            
        except Exception as e:
            print(f"ğŸ’¥ Worker {self.worker_id}: Chromeé©±åŠ¨åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def run(self):
        """å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯"""
        print(f"ğŸš€ Worker {self.worker_id}: å¯åŠ¨")
        
        # åˆ›å»ºæŒä¹…åŒ–driver
        try:
            self.driver = self.create_driver()
        except Exception as e:
            print(f"ğŸ’¥ Worker {self.worker_id}: æ— æ³•åˆ›å»ºdriverï¼Œé€€å‡º: {e}")
            return
        
        try:
            while not self.stop_event.is_set():
                try:
                    task = None
                    task_source = None
                    
                    # é¦–å…ˆæ£€æŸ¥é‡è¯•é˜Ÿåˆ—ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
                    try:
                        task = self.retry_queue.get_nowait()
                        task_source = 'retry'
                    except queue.Empty:
                        # é‡è¯•é˜Ÿåˆ—ä¸ºç©ºï¼Œä»ä¸»ä»»åŠ¡é˜Ÿåˆ—è·å–
                        task = self.task_queue.get(timeout=1.0)
                        task_source = 'main'
                    
                    # å¤„ç†ä»»åŠ¡
                    result = self.process_task(task)
                    
                    # æäº¤ç»“æœ
                    self.result_queue.put(result)
                    
                    # æ ‡è®°ä»»åŠ¡å®Œæˆ
                    if task_source == 'retry':
                        self.retry_queue.task_done()
                    else:
                        self.task_queue.task_done()
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.processed_count += 1
                    if result['success']:
                        self.success_count += 1
                    else:
                        self.error_count += 1
                    
                    # ğŸ”§ æ—¥å¿—å‹ç¼© - åªåœ¨æ¯100æ¡æˆ–verboseæ¨¡å¼æ—¶æ‰“å°
                    if self.verbose or self.processed_count % 100 == 0:
                        print(f"ğŸ“Š Worker {self.worker_id}: å·²å¤„ç† {self.processed_count} ä¸ªä»»åŠ¡ "
                              f"(æˆåŠŸ: {self.success_count}, å¤±è´¥: {self.error_count})")
                    
                    # å®šæœŸæ¸…ç†æµè§ˆå™¨ç¼“å­˜
                    if self.processed_count % 100 == 0:
                        try:
                            self.driver.delete_all_cookies()
                            self.driver.execute_script("window.gc();")
                        except:
                            pass
                    
                    # æ¯1000ä¸ªä»»åŠ¡é‡å¯worker
                    if self.processed_count % 1000 == 0 and self.processed_count > 0:
                        print(f"ğŸ”„ Worker {self.worker_id}: è¾¾åˆ°1000ä¸ªä»»åŠ¡ï¼Œé‡å¯Chromeé©±åŠ¨...")
                        try:
                            # å…³é—­å½“å‰driver
                            if self.driver:
                                self.driver.quit()
                            # åˆ›å»ºæ–°çš„driver
                            self.driver = self.create_driver()
                            print(f"âœ… Worker {self.worker_id}: Chromeé©±åŠ¨é‡å¯æˆåŠŸ")
                        except Exception as e:
                            print(f"âŒ Worker {self.worker_id}: Chromeé©±åŠ¨é‡å¯å¤±è´¥: {e}")
                            # å¦‚æœé‡å¯å¤±è´¥ï¼Œå°è¯•ç»§ç»­ä½¿ç”¨ç°æœ‰driveræˆ–é€€å‡º
                            if not self.driver:
                                print(f"ğŸ’¥ Worker {self.worker_id}: æ— æ³•ç»§ç»­ï¼Œé€€å‡ºå·¥ä½œçº¿ç¨‹")
                                break
                    
                except queue.Empty:
                    # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                    continue
                except Exception as e:
                    if self.verbose:
                        print(f"âŒ Worker {self.worker_id}: å¤„ç†ä»»åŠ¡å¼‚å¸¸: {e}")
                    continue
                    
        finally:
            # æ¸…ç†èµ„æº
            if self.driver:
                try:
                    self.driver.quit()
                    if self.verbose:
                        print(f"ğŸ§¹ Worker {self.worker_id}: é©±åŠ¨å·²æ¸…ç†")
                except:
                    pass
            
            print(f"ğŸ Worker {self.worker_id}: å®Œæˆï¼Œå…±å¤„ç† {self.processed_count} ä¸ªä»»åŠ¡ "
                  f"(æˆåŠŸ: {self.success_count}, å¤±è´¥: {self.error_count})")
    
    def process_task(self, task):
        """å¤„ç†å•ä¸ªPOIæå–ä»»åŠ¡"""
        address = task['address']
        index = task['index']
        original_address = task.get('original_address')
        is_retry = task.get('is_retry', False)
        
        try:
            # è°ƒç”¨ç°æœ‰çš„POIæå–é€»è¾‘ï¼Œä¼ é€’é‡è¯•æ ‡è¯†
            result = self.crawl_poi_info(address, is_retry=is_retry)
            
            if result.get('status') == 'success':
                return {
                    'success': True,
                    'data': result.get('data'),
                    'address': address,
                    'original_address': original_address,
                    'index': index,
                    'worker_id': self.worker_id,
                    'poi_count': result.get('poi_count', 0),
                    'result_type': result.get('result_type', 'unknown'),
                    'is_building': result.get('is_building', False),
                    'is_retry': is_retry
                }
            else:
                return {
                    'success': False,
                    'error': result.get('error_message', 'POIæå–å¤±è´¥'),
                    'address': address,
                    'original_address': original_address,
                    'index': index,
                    'worker_id': self.worker_id,
                    'poi_count': result.get('poi_count', 0),
                    'result_type': result.get('result_type', 'unknown'),
                    'is_building': result.get('is_building', False),
                    'is_retry': is_retry
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'address': address,
                'original_address': original_address,
                'index': index,
                'worker_id': self.worker_id,
                'poi_count': 0,
                'result_type': 'exception_error',
                'is_building': False,
                'is_retry': is_retry
            }
    
    def crawl_poi_info(self, address, is_retry=False):
        """POIä¿¡æ¯çˆ¬å– - åŸºäºç°æœ‰ä»£ç ç®€åŒ–ç‰ˆï¼Œæ”¯æŒå¿«é€Ÿé‡è¯•æ¨¡å¼"""
        url = f'https://www.google.com/maps/place/{address}'
        
        # æ·»åŠ åœ°å€å¤„ç†å¼€å§‹æ—¥å¿—
        if self.verbose:
            print(f"ğŸ” å¤„ç†åœ°å€: {address[:50]}{'...' if len(address) > 50 else ''}")
        
        try:
            self.driver.get(url)
            
            # ç­‰å¾…é¡µé¢åŸºæœ¬åŠ è½½
            time.sleep(1)  # ç»™é¡µé¢ä¸€ç‚¹æ—¶é—´å¼€å§‹è·³è½¬
            
            # æ—©æœŸæ£€æµ‹ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å»ºç­‘ç‰©é¡µé¢
            if not self.is_valid_building_page():
                print(f"âš ï¸  {address[:30]}{'...' if len(address) > 30 else ''}  | çŠ¶æ€: æ— æ•ˆåœ°å€é¡µé¢")
                return {
                    'data': None,
                    'status': 'success',  # æ ‡è®°ä¸ºæˆåŠŸä»¥è§¦å‘é‡è¯•
                    'result_type': 'invalid_address',  # æ–°çš„ç»“æœç±»å‹
                    'poi_count': 0,
                    'is_building': False
                }
            
            # å¿«é€Ÿæ£€æŸ¥é…’åº—ç±»åˆ«é¡µé¢
            if has_hotel_category(self.driver,address):
                if self.verbose:
                    print(f"ğŸ¨ æ£€æµ‹åˆ°é…’åº—é¡µé¢ï¼Œè·³è¿‡å¤„ç†: {address[:50]}")
                return {
                    'data': None,
                    'status': 'success',
                    'result_type': 'hotel_category_page',
                    'poi_count': 0,
                    'is_building': False
                }
            
            poi_count = 0
            #place_type = 'unknown'
            #is_building = False

            try:
                place_name = get_building_name(self.driver)
            except Exception as e:
                # å°è¯•å¤‡ç”¨æ–¹æ¡ˆè·å–åœ°ç‚¹åç§°
                place_name = self._get_fallback_location_name(self.driver, address) or 'Unknown Location'
                    
         
            try:
                more_button = self.driver.find_elements('class name', 'M77dve')
                if more_button:
                    click_on_more_button(self.driver)
                    scroll_poi_section(self.driver)
            except:
                pass
        


            df = get_all_poi_info(self.driver)

            if df is not None and not df.empty:
            
                poi_count = len(df)
                # è·å–åæ ‡
                
                final_url = wait_for_coords_url(self.driver)
                if final_url:
                    lat, lng = get_coords(final_url)
                else:
                    lat, lng = None, None

                
                df['blt_name'] = place_name
                df['lat'] = lat
                df['lng'] = lng
                
                # å•åœ°å€å®Œæˆæ€»ç»“ - å§‹ç»ˆæ˜¾ç¤ºæˆåŠŸå¤„ç†çš„åœ°å€
                print(f"âœ… {address[:30]}{'...' if len(address) > 30 else ''}  | POI: {poi_count} | çŠ¶æ€: å·²ä¿å­˜")


                return {
                            'data': df,
                            'status': 'success',
                            'result_type': 'building_with_poi',
                            'poi_count': poi_count,
                            'is_building': True
                        }
 
            else:
                
                place_type = get_building_type(self.driver)
                is_building = place_type == 'å»ºç­‘ç‰©' or place_type == 'å»ºé€ ç‰©'
                if is_building:
                    print(f"ğŸ¢ {address[:30]}{'...' if len(address) > 30 else ''}  | ç±»å‹: {place_type} | POI: 0 | éå•†ä¸šå»ºç­‘")
                    
                    return {
                        'data': None,
                        'status': 'success',
                        'result_type': 'building_no_poi',
                        'poi_count': 0,
                        'is_building': True
                    }
                else:
                    print(f"âŒ {address[:30]}{'...' if len(address) > 30 else ''}  | çŠ¶æ€: éå»ºç­‘ç‰©")
                    return {
                        'data': None,
                        'status': 'success',  # æ”¹ä¸ºsuccessï¼Œè¿™æ ·æ‰èƒ½è§¦å‘é‡è¯•
                        'result_type': 'not_building',
                        'poi_count': 0,
                        'is_building': False
                    }
                
        except TimeoutException:
            print(f"â° {address[:30]}{'...' if len(address) > 30 else ''}  | é”™è¯¯: é¡µé¢åŠ è½½è¶…æ—¶")
            return {
                'data': None,
                'status': 'error',
                'error_message': 'é¡µé¢åŠ è½½è¶…æ—¶',
                'result_type': 'timeout_error',
                'poi_count': 0,
                'is_building': False
            }
        except Exception as e:
            print(f"ğŸ’¥ {address[:30]}{'...' if len(address) > 30 else ''}  | é”™è¯¯: {str(e)[:50]}")
            return {
                'data': None,
                'status': 'error',
                'error_message': str(e),
                'result_type': 'processing_error',
                'poi_count': 0,
                'is_building': False
            }

    
    
    def is_valid_building_page(self):
        """ä»…ç”¨H1åˆ¤æ–­é¡µé¢æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å»ºç­‘ç‰©é¡µé¢"""
        try:
            # ç­‰å¾…é¡µé¢åŸºæœ¬åŠ è½½
            WebDriverWait(self.driver, 3).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # å°è¯•è·å–H1
            h1_elements = self.driver.find_elements(By.TAG_NAME, "h1")
            if h1_elements and h1_elements[0].text.strip():
                # æœ‰æœ‰æ•ˆçš„H1æ ‡é¢˜ï¼Œæ˜¯å»ºç­‘ç‰©é¡µé¢
                return True
            
            # æ²¡æœ‰H1æˆ–H1ä¸ºç©ºï¼Œæ˜¯æ— æ•ˆåœ°å€é¡µé¢
            return False
            
        except:
            # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ï¼Œå½“ä½œæ— æ•ˆé¡µé¢
            return False
    
    def _get_fallback_location_name(self, driver, address):
        """è·å–å¤‡ç”¨ä½ç½®åç§°"""
        try:
            # å°è¯•å¤šç§é€‰æ‹©å™¨è·å–ä½ç½®åç§°
            selectors = [
                "h1.DUwDvf",
                "h1.x3AX1-LfntMc-header-title-title", 
                "h1.bwoZTb",
                "h2.qrShPb",
                "span.DUwDvf"
            ]
            
            for selector in selectors:
                try:
                    element = driver.find_element("css selector", selector)
                    if element and element.text.strip():
                        return element.text.strip()
                except:
                    continue
            
            # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›åœ°å€çš„ç®€åŒ–ç‰ˆæœ¬
            return address.split(',')[0] if ',' in address else address
            
        except:
            return "Unknown Location"


class ResultBuffer:
    """ç»“æœç¼“å­˜æ±  - å®šæœŸè½ç›˜"""
    
    def __init__(self, output_file, batch_size=50, flush_interval=30, verbose=False, crawler_instance=None):
        self.output_file = Path(output_file)
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.verbose = verbose
        self.crawler_instance = crawler_instance
        self.buffer = []
        self.lock = threading.Lock()
        self.last_flush_time = time.time()
        self.total_saved = 0
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤´éƒ¨
        self.create_header()
        
        # å¯åŠ¨å®šæœŸåˆ·æ–°çº¿ç¨‹
        self.flush_thread = threading.Thread(target=self.auto_flush, daemon=True)
        self.flush_thread.start()
    
    def create_header(self):
        """åˆ›å»ºCSVæ–‡ä»¶å¤´éƒ¨ - æ”¯æŒæ–­ç‚¹ç»­ä¼ """
        if not self.output_file.exists():
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
            header_df = pd.DataFrame(columns=['name', 'rating', 'class', 'add', 'comment_count', 'blt_name', 'lat', 'lng'])
            header_df.to_csv(self.output_file, index=False, encoding='utf-8-sig')
            if self.verbose:
                print(f"ğŸ“ åˆ›å»ºè¾“å‡ºæ–‡ä»¶: {self.output_file}")
        else:
            # æ–‡ä»¶å­˜åœ¨ï¼Œæ£€æŸ¥æ–­ç‚¹ç»­ä¼ æƒ…å†µ
            try:
                # è¯»å–ç°æœ‰æ–‡ä»¶æ£€æŸ¥æ•°æ®çŠ¶æ€
                existing_df = pd.read_csv(self.output_file, encoding='utf-8-sig')
                if existing_df.empty:
                    # æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©ºï¼Œé‡æ–°åˆ›å»ºå¤´éƒ¨
                    header_df = pd.DataFrame(columns=['name', 'rating', 'class', 'add', 'comment_count', 'blt_name', 'lat', 'lng'])
                    header_df.to_csv(self.output_file, index=False, encoding='utf-8-sig')
                    if self.verbose:
                        print(f"ğŸ“ é‡æ–°åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤´éƒ¨: {self.output_file}")
                else:
                    if self.verbose:
                        print(f"ğŸ“ ç»§ç»­ä½¿ç”¨ç°æœ‰è¾“å‡ºæ–‡ä»¶: {self.output_file} (å·²æœ‰{len(existing_df)}æ¡æ•°æ®)")
            except Exception as e:
                if self.verbose:
                    print(f"âš ï¸ è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥ï¼Œé‡æ–°åˆ›å»º: {e}")
                # å‡ºé”™æ—¶é‡æ–°åˆ›å»ºæ–‡ä»¶
                header_df = pd.DataFrame(columns=['name', 'rating', 'class', 'add', 'comment_count', 'blt_name', 'lat', 'lng'])
                header_df.to_csv(self.output_file, index=False, encoding='utf-8-sig')
    
    def add_result(self, result):
        """æ·»åŠ ç»“æœåˆ°ç¼“å­˜æ±  - ğŸ”§ POIä¸ºç©ºæ—¶å¿«é€Ÿè·³è¿‡"""
        # å¿«é€Ÿè·³è¿‡å¤±è´¥æˆ–æ— æ•°æ®çš„ç»“æœ
        if not result['success']:
            return
            
        # ğŸ”§ POIä¿¡æ¯ä¸ºç©ºæ—¶å¿«é€Ÿè·³è¿‡ï¼Œé¿å…æ— æ„ä¹‰å†™å…¥
        poi_count = result.get('poi_count', 0)
        if poi_count == 0:
            return
            
        data = result.get('data')
        if data is None:
            return
        
        if isinstance(data, pd.DataFrame) and not data.empty:
            with self.lock:
                self.buffer.append(data)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ·æ–°
                if len(self.buffer) >= self.batch_size:
                    self._flush_to_disk()
    
    def auto_flush(self):
        """å®šæœŸè‡ªåŠ¨åˆ·æ–°åˆ°ç£ç›˜"""
        while True:
            time.sleep(self.flush_interval)
            current_time = time.time()
            
            with self.lock:
                if (self.buffer and 
                    current_time - self.last_flush_time >= self.flush_interval):
                    self._flush_to_disk()
    
    def _flush_to_disk(self):
        """åˆ·æ–°ç¼“å­˜åˆ°ç£ç›˜ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œéœ€è¦æŒæœ‰é”ï¼‰"""
        if not self.buffer:
            return
        
        # æ£€æŸ¥ä¸­æ–­æ ‡å¿—
        if self.crawler_instance and self.crawler_instance.interrupt_flag.is_set():
            if self.verbose:
                print("âš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œè·³è¿‡æ•°æ®å†™å…¥")
            return
        
        try:
            # åˆå¹¶æ‰€æœ‰DataFrame
            combined_df = pd.concat(self.buffer, ignore_index=True)
            
            # è¿½åŠ åˆ°æ–‡ä»¶
            combined_df.to_csv(self.output_file, mode='a', header=False, 
                             index=False, encoding='utf-8-sig')
            
            self.total_saved += len(combined_df)
            if self.verbose or len(combined_df) >= 20:  # åªåœ¨å¤§æ‰¹æ¬¡æˆ–verboseæ¨¡å¼æ—¶æ‰“å°
                print(f"ğŸ’¾ æ‰¹æ¬¡ä¿å­˜: {len(combined_df)} æ¡æ•°æ® (ç´¯è®¡: {self.total_saved})")
            
            # æ¸…ç©ºç¼“å­˜
            self.buffer = []
            self.last_flush_time = time.time()
            
        except Exception as e:
            print(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")
    
    def final_flush(self):
        """æœ€ç»ˆåˆ·æ–°æ‰€æœ‰å‰©ä½™æ•°æ®"""
        with self.lock:
            if self.buffer and not (self.crawler_instance and self.crawler_instance.interrupt_flag.is_set()):
                self._flush_to_disk()
                print(f"âœ… æœ€ç»ˆä¿å­˜å®Œæˆï¼Œæ€»è®¡: {self.total_saved} æ¡æ•°æ®")
            elif self.crawler_instance and self.crawler_instance.interrupt_flag.is_set():
                print(f"âš ï¸  ç”±äºä¸­æ–­ï¼Œè·³è¿‡æœ€ç»ˆæ•°æ®å†™å…¥ï¼Œå·²ä¿å­˜: {self.total_saved} æ¡æ•°æ®")


class SimplePOICrawler:
    """ç®€åŒ–ç‰ˆPOIçˆ¬è™« - 10ä¸ªæŒä¹…åŒ–Chromeå·¥ä½œçº¿ç¨‹"""
    
    def __init__(self, num_workers=10, batch_size=50, flush_interval=30, verbose=False, enable_resume=True, show_progress=True):
        self.num_workers = num_workers
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.verbose = verbose
        self.enable_resume = enable_resume
        
        # ä»»åŠ¡å’Œç»“æœé˜Ÿåˆ—
        self.task_queue = queue.Queue()
        self.retry_queue = queue.Queue()  # ä¸“é—¨çš„é‡è¯•é˜Ÿåˆ—ï¼Œä¼˜å…ˆå¤„ç†
        self.result_queue = queue.Queue()
        self.stop_event = threading.Event()
        self.interrupt_flag = threading.Event()  # ä¸­æ–­æ ‡å¿—
        
        # å·¥ä½œçº¿ç¨‹
        self.workers = []
        
        # ç»“æœç¼“å­˜æ± 
        self.result_buffer = None
        
        # æ–­ç‚¹ç»­ä¼ æ”¯æŒ
        self.progress_dir = Path("data/progress")
        self.progress_dir.mkdir(parents=True, exist_ok=True)
        self.progress_file = None
        self.processed_indices = set()  # å·²å¤„ç†çš„ç´¢å¼•
        self.current_file_name = None  # å½“å‰å¤„ç†çš„æ–‡ä»¶å
        self.current_output_file = None  # å½“å‰è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        # é‡è¯•ä¼˜åŒ–
        self.retry_cache = set()  # é‡è¯•åœ°å€ç¼“å­˜ï¼Œé¿å…é‡å¤é‡è¯•
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_tasks = 0
        self.processed_tasks = 0
        self.success_count = 0
        self.error_count = 0
        
        # è¿›åº¦æ¡æ”¯æŒ
        self.progress_bar = None
        self.show_progress = show_progress
        self.start_time = None
        self.progress_lock = threading.Lock()  # è¿›åº¦æ¡æ›´æ–°é”
        
        # è®¾ç½®ä¿¡å·å¤„ç†å™¨
        self._setup_signal_handlers()
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨ç”¨äºå®‰å…¨ä¸­æ–­"""
        def signal_handler(signum, frame):
            print("\nğŸš¨ æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å· (Ctrl+C)ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
            self.interrupt_flag.set()
            self.stop_event.set()
            
            # å…³é—­è¿›åº¦æ¡
            if self.progress_bar:
                with self.progress_lock:
                    self.progress_bar.close()
                    self.progress_bar = None
            
            print("ğŸ”„ æ­£åœ¨åœæ­¢å·¥ä½œçº¿ç¨‹å’Œæ¸…ç†èµ„æº...")
        
        signal.signal(signal.SIGINT, signal_handler)
        if hasattr(signal, 'SIGTERM'):  # Windows ä¸Šå¯èƒ½æ²¡æœ‰ SIGTERM
            signal.signal(signal.SIGTERM, signal_handler)
    
    def discover_input_files(self, pattern="data/input/*åŒº_*.csv"):
        """å‘ç°è¾“å…¥æ–‡ä»¶ - æ”¯æŒ--allåŠŸèƒ½"""
        files = glob.glob(pattern)
        csv_files = [f for f in files if f.endswith('.csv')]
        csv_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
        
        if self.verbose:
            print(f"ğŸ” å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶:")
            for f in csv_files:
                print(f"  - {f}")
        
        return csv_files
    
    def load_files_from_txt(self, txt_file):
        """ä».txtæ–‡æ¡£åŠ è½½æ–‡ä»¶åˆ—è¡¨"""
        try:
            with open(txt_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            files = []
            for line in lines:
                line = line.strip()
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                if line and not line.startswith('#'):
                    # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
                    if not os.path.isabs(line):
                        line = os.path.join('data/input', line)
                    
                    if os.path.exists(line) and line.endswith('.csv'):
                        files.append(line)
                    elif self.verbose:
                        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨æˆ–éCSV: {line}")
            
            if self.verbose:
                print(f"ğŸ“‹ ä» {txt_file} åŠ è½½äº† {len(files)} ä¸ªæ–‡ä»¶")
            
            return files
            
        except Exception as e:
            print(f"âŒ åŠ è½½TXTæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def load_addresses_from_csv(self, csv_file):
        """ä»CSVæ–‡ä»¶åŠ è½½åœ°å€"""
        try:
            df = pd.read_csv(csv_file)
            addresses = []
            
            for index, row in df.iterrows():
                # ä¼˜å…ˆä½¿ç”¨FormattedAddressï¼Œç„¶åAddressï¼Œæœ€åConvertedAddress
                address = None
                original_address = None
                
                if 'FormattedAddress' in df.columns and pd.notna(row['FormattedAddress']):
                    address = row['FormattedAddress'].strip()
                elif 'Address' in df.columns and pd.notna(row['Address']):
                    address = row['Address']
                elif 'ConvertedAddress' in df.columns and pd.notna(row['ConvertedAddress']):
                    address = row['ConvertedAddress'].strip()
                
                # ä¿å­˜æ—¥æ–‡åŸå§‹åœ°å€ç”¨äºé‡è¯•
                if 'Address' in df.columns and pd.notna(row['Address']):
                    original_address = row['Address']
                
                if address:
                    addresses.append({
                        'address': address,
                        'original_address': original_address,
                        'index': index
                    })
            
            print(f"ğŸ“‹ åŠ è½½åœ°å€: {len(addresses)} æ¡")
            return addresses
            
        except Exception as e:
            print(f"âŒ åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _extract_file_name(self, file_path):
        """ä»æ–‡ä»¶è·¯å¾„æå–æ–‡ä»¶åä½œä¸ºè¿›åº¦æ ‡è¯†"""
        return Path(file_path).stem
    
    def _get_last_processed_index(self):
        """è·å–æœ€åä¸€ä¸ªå¤„ç†çš„ç´¢å¼•"""
        if not self.processed_indices:
            return -1
        return max(self.processed_indices)
    
    def _save_progress(self):
        """ä¿å­˜å½“å‰è¿›åº¦åˆ°JSONæ–‡ä»¶ - ä¼˜åŒ–ç‰ˆï¼ˆåªä¿å­˜æœ€åå¤„ç†çš„ç´¢å¼•ï¼‰"""
        if not self.enable_resume or not self.progress_file or self.interrupt_flag.is_set():
            return
        
        try:
            # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰è¿›åº¦æ–‡ä»¶ï¼Œä¿æŒåŸå§‹æ—¶é—´æˆ³
            existing_timestamp = None
            if self.progress_file.exists():
                try:
                    with open(self.progress_file, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                        existing_timestamp = existing_data.get('timestamp')
                except:
                    pass  # å¦‚æœè¯»å–å¤±è´¥ï¼Œå°±ä½¿ç”¨æ–°çš„æ—¶é—´æˆ³
            
            progress_data = {
                'file_name': self.current_file_name,
                'output_file': str(self.current_output_file) if self.current_output_file else None,
                'last_processed_index': self._get_last_processed_index(),
                'total_tasks': self.total_tasks,
                'processed_tasks': self.processed_tasks,
                'success_count': self.success_count,
                'error_count': self.error_count,
                'timestamp': existing_timestamp if existing_timestamp is not None else time.time(),  # ä¿æŒåŸæ—¶é—´æˆ³æˆ–åˆ›å»ºæ–°çš„
                'last_updated': time.time()  # æ·»åŠ æœ€åæ›´æ–°æ—¶é—´
            }
            
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
                
            if self.verbose:
                print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {self.processed_tasks}/{self.total_tasks}, æœ€åç´¢å¼•: {self._get_last_processed_index()}")
                
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def _load_progress(self, file_name):
        """åŠ è½½è¿›åº¦æ–‡ä»¶"""
        if not self.enable_resume:
            return None
        
        progress_file = self.progress_dir / f"{file_name}_simple_progress.json"
        
        if not progress_file.exists():
            return None
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªæ–‡ä»¶çš„è¿›åº¦
            if progress_data.get('file_name') == file_name:
                # è¾“å‡ºæ–‡ä»¶è·¯å¾„ç”¨äºè°ƒè¯•å’ŒéªŒè¯
                if self.verbose and 'output_file' in progress_data:
                    last_index = progress_data.get('last_processed_index', -1)
                    print(f"ğŸ“ ä»è¿›åº¦æ–‡ä»¶åŠ è½½: è¾“å‡ºè·¯å¾„={progress_data['output_file']}, æœ€åç´¢å¼•={last_index}")
                return progress_data
                
        except (json.JSONDecodeError, KeyError, FileNotFoundError) as e:
            print(f"âš ï¸  è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
        
        return None
    
    def _cleanup_progress(self):
        """æ¸…ç†è¿›åº¦æ–‡ä»¶"""
        if self.progress_file and self.progress_file.exists():
            try:
                self.progress_file.unlink()
                if self.verbose:
                    print(f"ğŸ§¹ è¿›åº¦æ–‡ä»¶å·²æ¸…ç†: {self.progress_file.name}")
            except Exception as e:
                print(f"âš ï¸  æ¸…ç†è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
    
    def start_workers(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        print(f"ğŸš€ å¯åŠ¨ {self.num_workers} ä¸ªChromeå·¥ä½œçº¿ç¨‹...")
        
        for i in range(self.num_workers):
            worker = ChromeWorker(i, self.task_queue, self.result_queue, self.stop_event, self.verbose, self.retry_queue)
            worker.start()
            self.workers.append(worker)
            time.sleep(1)  # é”™å¼€å¯åŠ¨æ—¶é—´ï¼Œé¿å…å¹¶å‘åˆ›å»ºdriver
        
        print(f"âœ… æ‰€æœ‰å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_workers(self):
        """åœæ­¢å·¥ä½œçº¿ç¨‹"""
        if not self.interrupt_flag.is_set():
            print("ğŸ›‘ åœæ­¢æ‰€æœ‰å·¥ä½œçº¿ç¨‹...")
        
        # è®¾ç½®åœæ­¢äº‹ä»¶
        self.stop_event.set()
        
        # å¦‚æœæ˜¯ä¸­æ–­ï¼Œä¸ç­‰å¾…é˜Ÿåˆ—å®Œæˆï¼Œç›´æ¥åœæ­¢
        if not self.interrupt_flag.is_set():
            self.task_queue.join()
        
        # ç­‰å¾…å·¥ä½œçº¿ç¨‹ç»“æŸï¼ˆä¸­æ–­æ—¶æ›´çŸ­çš„è¶…æ—¶ï¼‰
        timeout = 1 if self.interrupt_flag.is_set() else 5
        for worker in self.workers:
            worker.join(timeout=timeout)
        
        if not self.interrupt_flag.is_set():
            print("âœ… æ‰€æœ‰å·¥ä½œçº¿ç¨‹å·²åœæ­¢")
        else:
            print("âœ… å·¥ä½œçº¿ç¨‹å·²å¿«é€Ÿåœæ­¢")
    
    def process_results(self):
        """å¤„ç†ç»“æœé˜Ÿåˆ—"""
        print("ğŸ“Š å¯åŠ¨ç»“æœå¤„ç†çº¿ç¨‹...")
        
        while not self.stop_event.is_set() or not self.result_queue.empty():
            # æ£€æŸ¥ä¸­æ–­æ ‡å¿—
            if self.interrupt_flag.is_set():
                print("âš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œç»“æœå¤„ç†çº¿ç¨‹é€€å‡º")
                break
                
            try:
                result = self.result_queue.get(timeout=1.0)
                
                # æ·»åŠ åˆ°ç¼“å­˜æ± 
                self.result_buffer.add_result(result)
                
                # è®°å½•å·²å¤„ç†çš„ç´¢å¼•ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
                if 'index' in result and not result.get('is_retry', False):
                    self.processed_indices.add(result['index'])
                
                # æ›´æ–°ç»Ÿè®¡
                self.processed_tasks += 1
                if result['success']:
                    self.success_count += 1
                else:
                    self.error_count += 1
                
                # æ›´æ–°è¿›åº¦æ¡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                if self.progress_bar:
                    with self.progress_lock:
                        self.progress_bar.update(1)
                        # æ¯5ä¸ªä»»åŠ¡æ›´æ–°ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„æ›´æ–°
                        if self.processed_tasks % 5 == 0:
                            self._update_progress_bar()
                
                # å®šæœŸä¿å­˜è¿›åº¦ï¼ˆæ¯å¤„ç†10ä¸ªä»»åŠ¡ä¿å­˜ä¸€æ¬¡ï¼‰
                if self.processed_tasks % 10 == 0 and not self.interrupt_flag.is_set():
                    self._save_progress()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨æ—¥æ–‡åœ°å€é‡è¯•
                # åªå¯¹æ— æ•ˆåœ°å€è¿›è¡Œé‡è¯•
                if (result['success'] and 
                    result.get('result_type') == 'invalid_address' and  # åªé‡è¯•æ— æ•ˆåœ°å€
                    result.get('original_address') and 
                    result['address'] != result['original_address'] and
                    not result.get('is_retry', False) and  # é¿å…é‡å¤é‡è¯•
                    result.get('original_address') not in self.retry_cache):  # æ£€æŸ¥ç¼“å­˜
                    
                    original_address = result.get('original_address')
                    
                    # è®°å½•åˆ°é‡è¯•ç¼“å­˜
                    self.retry_cache.add(original_address)
                    
                    # ä½¿ç”¨æ—¥æ–‡åœ°å€é‡è¯•
                    print(f"ğŸ”„ æ— æ•ˆåœ°å€ï¼Œä½¿ç”¨æ—¥æ–‡åœ°å€é‡è¯•: {original_address[:30]}...")
                    
                    retry_task = {
                        'address': original_address,
                        'index': result['index'],
                        'original_address': original_address,
                        'is_retry': True
                    }
                    # æ”¾å…¥ä¼˜å…ˆçº§é‡è¯•é˜Ÿåˆ—ï¼Œç«‹å³å¤„ç†
                    self.retry_queue.put(retry_task)
                    # å¢åŠ æ€»ä»»åŠ¡æ•°ä»¥åŒ…å«é‡è¯•ä»»åŠ¡
                    self.total_tasks += 1
                
                # è°ƒè¯•ï¼šè®°å½•æ‰€æœ‰result_typeçš„åˆ†å¸ƒï¼ˆåªåœ¨verboseæ¨¡å¼ï¼‰
                if self.verbose and self.processed_tasks % 50 == 0:
                    print(f"ğŸ“Š Resultç±»å‹: {result.get('result_type', 'unknown')} | é‡è¯•: {result.get('is_retry', False)}")
                
                # ğŸ”§ æ—¥å¿—å‹ç¼© - å®šæœŸæŠ¥å‘Šè¿›åº¦
                if self.verbose or self.processed_tasks % 200 == 0:
                    progress = (self.processed_tasks / self.total_tasks * 100) if self.total_tasks > 0 else 0
                    print(f"ğŸ“ˆ æ€»è¿›åº¦: {self.processed_tasks}/{self.total_tasks} ({progress:.1f}%) "
                          f"- æˆåŠŸ: {self.success_count}, å¤±è´¥: {self.error_count}")
                
                self.result_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ å¤„ç†ç»“æœå¼‚å¸¸: {e}")
                continue
    
    def _setup_file_processing(self, input_file, output_file=None):
        """è®¾ç½®æ–‡ä»¶å¤„ç†çš„æ–­ç‚¹ç»­ä¼ å‚æ•° - ç»Ÿä¸€æ¥å£"""
        self.current_file_name = self._extract_file_name(input_file)
        self.progress_file = self.progress_dir / f"{self.current_file_name}_simple_progress.json"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„è¿›åº¦
        progress_data = self._load_progress(self.current_file_name)
        
        # ğŸ”§ æ–­ç‚¹ç»­ä¼ ï¼šä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        if progress_data and 'output_file' in progress_data:
            self.current_output_file = progress_data['output_file']
            print(f"ğŸ”„ å‘ç°æœªå®Œæˆçš„ä»»åŠ¡ï¼Œä»æ–­ç‚¹ç»§ç»­...")
            print(f"ğŸ“Š ä¹‹å‰è¿›åº¦: {progress_data['processed_tasks']}/{progress_data['total_tasks']}")
            print(f"ğŸ“ ç»­ä¼ è¾“å‡ºæ–‡ä»¶: {self.current_output_file}")
            
            # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ä¸åŒçš„è¾“å‡ºæ–‡ä»¶ï¼Œç»™å‡ºè­¦å‘Š
            if output_file and output_file != self.current_output_file:
                print(f"âš ï¸  ç”¨æˆ·æŒ‡å®šçš„è¾“å‡ºæ–‡ä»¶ä¸æ–­ç‚¹ç»­ä¼ æ–‡ä»¶ä¸ä¸€è‡´:")
                print(f"   - æ–­ç‚¹ç»­ä¼ : {self.current_output_file}")
                print(f"   - ç”¨æˆ·æŒ‡å®š: {output_file}")
                print(f"   - å°†ä½¿ç”¨æ–­ç‚¹ç»­ä¼ æ–‡ä»¶: {self.current_output_file}")
        else:
            # æ²¡æœ‰è¿›åº¦æ•°æ®ï¼Œä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºæ–‡ä»¶
            if output_file:
                self.current_output_file = output_file
        
        # åŠ è½½åœ°å€
        addresses = self.load_addresses_from_csv(input_file)
        if not addresses:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆåœ°å€å¯å¤„ç†")
            return None
        
        # å¤„ç†æ–­ç‚¹ç»­ä¼ 
        if progress_data:
            # æ¢å¤ç»Ÿè®¡ä¿¡æ¯
            last_processed_index = progress_data.get('last_processed_index', -1)
            self.processed_tasks = progress_data.get('processed_tasks', 0)
            self.success_count = progress_data.get('success_count', 0)
            self.error_count = progress_data.get('error_count', 0)
            
            # é‡æ–°æ„å»º processed_indicesï¼ˆä» 0 åˆ° last_processed_indexï¼‰
            self.processed_indices = set(range(0, last_processed_index + 1)) if last_processed_index >= 0 else set()
            
            # è¿‡æ»¤å‡ºæœªå¤„ç†çš„åœ°å€ï¼ˆç´¢å¼•å¤§äº last_processed_indexï¼‰
            remaining_addresses = [addr for addr in addresses if addr['index'] > last_processed_index]
            print(f"ğŸ“‹ å‰©ä½™æœªå¤„ç†åœ°å€: {len(remaining_addresses)} æ¡ (ä»ç´¢å¼• {last_processed_index + 1} å¼€å§‹)")
            
            if not remaining_addresses:
                print("âœ… æ‰€æœ‰åœ°å€å·²å¤„ç†å®Œæˆï¼")
                self._cleanup_progress()
                return None
                
            addresses = remaining_addresses
        else:
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self.processed_indices = set()
            self.processed_tasks = 0
            self.success_count = 0
            self.error_count = 0
        
        self.total_tasks = len(addresses) + self.processed_tasks  # åŒ…å«å·²å¤„ç†çš„ä»»åŠ¡æ•°
        
        # åˆå§‹åŒ–è¿›åº¦æ¡
        if self.show_progress and self.total_tasks > 0:
            self.start_time = time.time()
            remaining_tasks = len(addresses)
            
            with self.progress_lock:
                # å…³é—­æ—§çš„è¿›åº¦æ¡
                if self.progress_bar:
                    self.progress_bar.close()
                
                # åˆ›å»ºæ–°çš„è¿›åº¦æ¡
                self.progress_bar = tqdm(
                    total=self.total_tasks,
                    initial=self.processed_tasks,
                    desc=f"ğŸ” {self.current_file_name[:12]}",
                    unit="æ¡",
                    ncols=90,
                    position=0,
                    leave=True,
                    bar_format='{desc}: {percentage:3.0f}%|{bar:20}| {n_fmt}/{total_fmt} {postfix}'
                )
                
                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                self._update_progress_bar()
        
        return addresses
    
    def _update_progress_bar(self):
        """æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºä¿¡æ¯ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œè°ƒç”¨æ—¶éœ€å·²è·å¾—é”ï¼‰"""
        if not self.progress_bar:
            return
            
        elapsed_time = time.time() - self.start_time if self.start_time else 0
        speed = self.processed_tasks / elapsed_time if elapsed_time > 0 else 0
        
        # è®¡ç®—æˆåŠŸç‡
        success_rate = (self.success_count / self.processed_tasks * 100) if self.processed_tasks > 0 else 0
        
        # ç®€åŒ–çš„postfixä¿¡æ¯
        if speed > 0:
            postfix = f"{success_rate:.0f}%æˆåŠŸ {speed:.1f}/s"
        else:
            postfix = f"{success_rate:.0f}%æˆåŠŸ å¯åŠ¨ä¸­"
        
        self.progress_bar.set_postfix_str(postfix)
    
    def _finalize_file_processing(self):
        """å®Œæˆæ–‡ä»¶å¤„ç†åçš„æ¸…ç†å·¥ä½œ - ç»Ÿä¸€æ¥å£"""
        # å…³é—­è¿›åº¦æ¡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        with self.progress_lock:
            if self.progress_bar:
                self.progress_bar.close()
                self.progress_bar = None
        
        # ä¿å­˜æœ€ç»ˆè¿›åº¦å¹¶æ¸…ç†ï¼ˆåªåœ¨æœªä¸­æ–­æ—¶ï¼‰
        if not self.interrupt_flag.is_set():
            self._save_progress()
            self._cleanup_progress()
        else:
            print("âš ï¸  ç”±äºä¸­æ–­ï¼Œè·³è¿‡æœ€ç»ˆè¿›åº¦ä¿å­˜å’Œæ¸…ç†")
    
    def process_single_file(self, input_file, output_file, workers_started=False):
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„ç»Ÿä¸€æ¥å£ - æ”¯æŒæ–­ç‚¹ç»­ä¼ """
        # è®¾ç½®æ–‡ä»¶å¤„ç†å‚æ•°
        addresses = self._setup_file_processing(input_file, output_file)
        if addresses is None:
            return {'success': False, 'reason': 'æ— åœ°å€æˆ–å·²å®Œæˆ'}
        
        # åˆå§‹åŒ–ç»“æœç¼“å­˜æ± 
        self.result_buffer = ResultBuffer(output_file, self.batch_size, self.flush_interval, self.verbose, self)
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹ï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
        if not workers_started:
            self.start_workers()
            
            # å¯åŠ¨ç»“æœå¤„ç†çº¿ç¨‹
            result_thread = threading.Thread(target=self.process_results, daemon=True)
            result_thread.start()
        
        try:
            # æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—
            print(f"ğŸ“¤ æ·»åŠ  {len(addresses)} ä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—...")
            for addr_data in addresses:
                self.task_queue.put(addr_data)
            
            # ç­‰å¾…å½“å‰æ–‡ä»¶çš„ä»»åŠ¡å®Œæˆ
            self.task_queue.join()
            
            # ç­‰å¾…ç»“æœå¤„ç†å®Œæˆ
            while not self.result_queue.empty():
                time.sleep(0.1)
            
            # æœ€ç»ˆåˆ·æ–°ç¼“å­˜
            if self.result_buffer:
                self.result_buffer.final_flush()
            
            # å®Œæˆæ–‡ä»¶å¤„ç†
            self._finalize_file_processing()
            
            return {
                'success': True, 
                'processed': self.processed_tasks,
                'success_count': self.success_count,
                'error_count': self.error_count
            }
            
        except Exception as e:
            # å³ä½¿å‡ºé”™ä¹Ÿä¿å­˜è¿›åº¦
            try:
                self._save_progress()
            except:
                pass
            return {'success': False, 'reason': str(e)}
    
    def crawl_from_csv(self, input_file, output_file):
        """ä»CSVæ–‡ä»¶çˆ¬å–POIæ•°æ® - æ”¯æŒæ–­ç‚¹ç»­ä¼ """
        print(f"â° ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...")
        start_time = time.time()
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„å¤„ç†æ¥å£
            result = self.process_single_file(input_file, output_file, workers_started=False)
            
            if not result['success']:
                print(f"âŒ å¤„ç†å¤±è´¥: {result.get('reason', 'æœªçŸ¥é”™è¯¯')}")
                return
            
            elapsed_time = time.time() - start_time
            
            print(f"ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
            print(f"â±ï¸  è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ")
            print(f"ğŸ“Š æ€»è®¡: {result['processed']} ä¸ªä»»åŠ¡")
            print(f"âœ… æˆåŠŸ: {result['success_count']}")
            print(f"âŒ å¤±è´¥: {result['error_count']}")
            if result['processed'] > 0:
                print(f"ğŸ“ˆ æˆåŠŸç‡: {(result['success_count']/result['processed']*100):.1f}%")
            
        except KeyboardInterrupt:
            # Ctrl+C å·²ç»ç”±ä¿¡å·å¤„ç†å™¨å¤„ç†ï¼Œè¿™é‡Œåªéœ€è¦é™é»˜é€€å‡º
            pass
        
        finally:
            # åœæ­¢å·¥ä½œçº¿ç¨‹
            self.stop_workers()
            
            if not self.interrupt_flag.is_set():
                print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            else:
                print(f"âš ï¸  ç”±äºä¸­æ–­ï¼Œéƒ¨åˆ†ç»“æœå¯èƒ½æœªä¿å­˜: {output_file}")
    
    def crawl_multiple_files(self, file_list, output_dir="data/output"):
        """æ‰¹é‡å¤„ç†å¤šä¸ªCSVæ–‡ä»¶"""
        if not file_list:
            print("âŒ æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†")
            return
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_list)} ä¸ªæ–‡ä»¶")
        print("="*60)
        
        all_success = 0
        all_errors = 0
        processed_files = []
        start_time = time.time()
        
        for i, file_path in enumerate(file_list):
            file_name = os.path.basename(file_path)
            print(f"\nğŸ“‚ å¤„ç†ç¬¬ {i+1}/{len(file_list)} ä¸ªæ–‡ä»¶: {file_name}")
            print("-" * 50)
            
            # ğŸ”§ æ™ºèƒ½è¾“å‡ºæ–‡ä»¶åç”Ÿæˆ - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            input_path = Path(file_path)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–­ç‚¹ç»­ä¼ çš„è¿›åº¦æ–‡ä»¶
            file_name = self._extract_file_name(file_path)
            progress_data = self._load_progress(file_name)
            
            if progress_data and 'output_file' in progress_data:
                # æ–­ç‚¹ç»­ä¼ ï¼šä½¿ç”¨ä¹‹å‰ä¿å­˜çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
                output_file = progress_data['output_file']
                print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ ï¼Œä½¿ç”¨ä¹‹å‰çš„è¾“å‡ºæ–‡ä»¶: {output_file}")
            else:
                # æ–°æ–‡ä»¶ï¼šç”Ÿæˆå”¯ä¸€çš„è¾“å‡ºæ–‡ä»¶å
                timestamp = int(time.time())
                import random
                unique_id = f"{timestamp}_{random.randint(1000, 9999)}"
                output_file = f"{output_dir}/{input_path.stem}_simple_{unique_id}.csv"
                print(f"ğŸ“ æ–°æ–‡ä»¶ï¼Œåˆ›å»ºè¾“å‡ºæ–‡ä»¶: {output_file}")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            Path(output_file).parent.mkdir(parents=True, exist_ok=True)
            
            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„å¤„ç†æ¥å£
                workers_already_started = (i > 0)  # ä»ç¬¬äºŒä¸ªæ–‡ä»¶å¼€å§‹ï¼Œå·¥ä½œçº¿ç¨‹å·²ç»å¯åŠ¨
                result = self.process_single_file(file_path, output_file, workers_already_started)
                
                if not result['success']:
                    processed_files.append(f"{file_name}: {result.get('reason', 'å¤„ç†å¤±è´¥')}")
                    continue
                
                # ç»Ÿè®¡ç»“æœ
                all_success += result['success_count']
                all_errors += result['error_count']
                processed_files.append(f"{file_name}: æˆåŠŸ{result['success_count']}, å¤±è´¥{result['error_count']}")
                
                print(f"âœ… {file_name} å®Œæˆ - æˆåŠŸ: {result['success_count']}, å¤±è´¥: {result['error_count']}")
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {e}")
                processed_files.append(f"{file_name}: å¤„ç†å¤±è´¥")
                continue
        
        # åœæ­¢å·¥ä½œçº¿ç¨‹
        self.stop_workers()
        
        # æ€»ç»“æŠ¥å‘Š
        total_time = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"{'='*60}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ“Š å¤„ç†æ–‡ä»¶: {len(processed_files)} ä¸ª")
        print(f"âœ… æ€»æˆåŠŸ: {all_success}")
        print(f"âŒ æ€»å¤±è´¥: {all_errors}")
        success_rate = (all_success / (all_success + all_errors) * 100) if (all_success + all_errors) > 0 else 0
        print(f"ğŸ“ˆ æ€»æˆåŠŸç‡: {success_rate:.1f}%")
        
        print(f"\nğŸ“‹ æ–‡ä»¶å¤„ç†è¯¦æƒ…:")
        for file_summary in processed_files:
            print(f"  {file_summary}")
        
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_dir}/")
        
        return all_success, all_errors


def main():
    parser = argparse.ArgumentParser(description='ç®€åŒ–ç‰ˆPOIçˆ¬è™« - 10ä¸ªæŒä¹…åŒ–Chromeå·¥ä½œçº¿ç¨‹')
    parser.add_argument('input_file', nargs='?', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--all', action='store_true', help='æ‰¹é‡å¤„ç†æ‰€æœ‰åŒºåŸŸæ–‡ä»¶ (data/input/*åŒº_*.csv)')
    parser.add_argument('--file-list', type=str, help='ä»TXTæ–‡ä»¶è¯»å–è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨')
    parser.add_argument('--pattern', type=str, help='ä½¿ç”¨é€šé…ç¬¦æ¨¡å¼é€‰æ‹©æ–‡ä»¶ï¼Œå¦‚ "data/input/*åŒº_complete*.csv"')
    parser.add_argument('--output', '-o', default=None, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå•æ–‡ä»¶æ¨¡å¼ï¼‰æˆ–è¾“å‡ºç›®å½•ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰')
    parser.add_argument('--workers', '-w', type=int, default=10, help='å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 10)')
    parser.add_argument('--batch-size', '-b', type=int, default=50, help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 50)')
    parser.add_argument('--flush-interval', '-f', type=int, default=30, help='åˆ·æ–°é—´éš”ç§’æ•° (é»˜è®¤: 30)')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ—¥å¿—è¾“å‡ºæ¨¡å¼')
    parser.add_argument('--no-resume', action='store_true', help='ç¦ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½')
    parser.add_argument('--no-progress', action='store_true', help='ç¦ç”¨è¿›åº¦æ¡æ˜¾ç¤º')
    
    args = parser.parse_args()
    
    # å‚æ•°éªŒè¯
    if not args.all and not args.file_list and not args.pattern and not args.input_file:
        parser.error("å¿…é¡»æä¾›è¾“å…¥æ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨ --allã€--file-listã€--pattern é€‰é¡¹ä¹‹ä¸€")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = SimplePOICrawler(
        num_workers=args.workers,
        batch_size=args.batch_size,
        flush_interval=args.flush_interval,
        verbose=args.verbose,
        enable_resume=not args.no_resume,
        show_progress=not args.no_progress
    )
    
    # ç¡®å®šè¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    file_list = []
    
    if args.all:
        # --all: è‡ªåŠ¨å‘ç°æ‰€æœ‰åŒºåŸŸæ–‡ä»¶
        file_list = crawler.discover_input_files()
        if not file_list:
            print("âŒ åœ¨ data/input/ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¨¡å¼çš„CSVæ–‡ä»¶")
            return
        print(f"ğŸ” --all æ¨¡å¼: å‘ç° {len(file_list)} ä¸ªæ–‡ä»¶")
        
    elif args.file_list:
        # --file-list: ä»TXTæ–‡ä»¶åŠ è½½
        if not os.path.exists(args.file_list):
            print(f"âŒ æ–‡ä»¶åˆ—è¡¨ä¸å­˜åœ¨: {args.file_list}")
            return
        file_list = crawler.load_files_from_txt(args.file_list)
        if not file_list:
            print(f"âŒ ä» {args.file_list} æ²¡æœ‰åŠ è½½åˆ°æœ‰æ•ˆçš„CSVæ–‡ä»¶")
            return
        print(f"ğŸ“‹ --file-list æ¨¡å¼: ä» {args.file_list} åŠ è½½äº† {len(file_list)} ä¸ªæ–‡ä»¶")
        
    elif args.pattern:
        # --pattern: ä½¿ç”¨é€šé…ç¬¦æ¨¡å¼
        file_list = crawler.discover_input_files(args.pattern)
        if not file_list:
            print(f"âŒ æ¨¡å¼ '{args.pattern}' æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•CSVæ–‡ä»¶")
            return
        print(f"ğŸ” --pattern æ¨¡å¼: æ¨¡å¼ '{args.pattern}' åŒ¹é…åˆ° {len(file_list)} ä¸ªæ–‡ä»¶")
        
    else:
        # å•æ–‡ä»¶æ¨¡å¼
        if not os.path.exists(args.input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
            return
        file_list = [args.input_file]
        print(f"ğŸ“„ å•æ–‡ä»¶æ¨¡å¼: {args.input_file}")
    
    # æ˜¾ç¤ºè¦å¤„ç†çš„æ–‡ä»¶
    if args.verbose and len(file_list) > 1:
        print(f"\nğŸ“‹ å°†è¦å¤„ç†çš„æ–‡ä»¶:")
        for i, f in enumerate(file_list, 1):
            print(f"  {i:2d}. {f}")
        print()
    
    # æ‰§è¡Œå¤„ç†
    if len(file_list) == 1:
        # å•æ–‡ä»¶å¤„ç†æ¨¡å¼
        input_file = file_list[0]
        
        # ğŸ”§ æ™ºèƒ½è¾“å‡ºæ–‡ä»¶åç”Ÿæˆ - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        if not args.output:
            input_path = Path(input_file)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–­ç‚¹ç»­ä¼ çš„è¿›åº¦æ–‡ä»¶
            file_name = crawler._extract_file_name(input_file)
            progress_data = crawler._load_progress(file_name)
            
            if progress_data and 'output_file' in progress_data:
                # æ–­ç‚¹ç»­ä¼ ï¼šä½¿ç”¨ä¹‹å‰ä¿å­˜çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
                args.output = progress_data['output_file']
                print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ ï¼Œä½¿ç”¨ä¹‹å‰çš„è¾“å‡ºæ–‡ä»¶: {args.output}")
            else:
                # æ–°æ–‡ä»¶ï¼šç”Ÿæˆå”¯ä¸€çš„è¾“å‡ºæ–‡ä»¶å
                timestamp = int(time.time())
                import random
                unique_id = f"{timestamp}_{random.randint(1000, 9999)}"
                args.output = f"data/output/{input_path.stem}_simple_{unique_id}.csv"
                print(f"ğŸ“ æ–°æ–‡ä»¶ï¼Œåˆ›å»ºè¾“å‡ºæ–‡ä»¶: {args.output}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(args.output).parent.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸš€ ç®€åŒ–ç‰ˆPOIçˆ¬è™«å¯åŠ¨")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output}")
        print(f"ğŸ‘¥ å·¥ä½œçº¿ç¨‹: {args.workers}")
        print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        print(f"â° åˆ·æ–°é—´éš”: {args.flush_interval}ç§’")
        print(f"ğŸ”Š è¯¦ç»†æ—¥å¿—: {'å¼€å¯' if args.verbose else 'å…³é—­'}")
        print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : {'å¼€å¯' if not args.no_resume else 'å…³é—­'}")
        print(f"ğŸ“Š è¿›åº¦æ¡: {'å¼€å¯' if not args.no_progress else 'å…³é—­'}")
        print("="*60)
        
        crawler.crawl_from_csv(input_file, args.output)
        
    else:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        output_dir = args.output if args.output else "data/output"
        
        print(f"ğŸš€ ç®€åŒ–ç‰ˆPOIçˆ¬è™«å¯åŠ¨ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰")
        print(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {len(file_list)} ä¸ª")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ‘¥ å·¥ä½œçº¿ç¨‹: {args.workers}")
        print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        print(f"â° åˆ·æ–°é—´éš”: {args.flush_interval}ç§’")
        print(f"ğŸ”Š è¯¦ç»†æ—¥å¿—: {'å¼€å¯' if args.verbose else 'å…³é—­'}")
        print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : {'å¼€å¯' if not args.no_resume else 'å…³é—­'}")
        print(f"ğŸ“Š è¿›åº¦æ¡: {'å¼€å¯' if not args.no_progress else 'å…³é—­'}")
        print("="*60)
        
        crawler.crawl_multiple_files(file_list, output_dir)


if __name__ == "__main__":
    main()